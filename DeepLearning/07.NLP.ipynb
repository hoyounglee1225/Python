{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4ed2fa",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632cbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version은 코랩 명령입니다.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 이 노트북은 텐서플로 ≥2.4이 필요합니다\n",
    "# 2.x 버전은 대부분 동일한 결과를 만들지만 몇 가지 버그가 있습니다.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"NLP\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "    \n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882efeb",
   "metadata": {},
   "source": [
    "## 양방향 LSTM을 이용한 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79a48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecbaa9",
   "metadata": {},
   "source": [
    "### 영어 코퍼스에 토큰화 와 품사 태깅 전처리를 진행한 문장 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7576c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅이 된 문장 개수:  3914\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents() # 토큰화에 품사 태깅이 된 데이터 받아오기\n",
    "print(\"품사 태깅이 된 문장 개수: \", len(tagged_sentences)) # 문장 샘플의 개수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5547bbe",
   "metadata": {},
   "source": [
    "### 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa63f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91502a33",
   "metadata": {},
   "source": [
    "### 단어는 sentences에 태깅 정보는 pos_tags에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cd8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
     ]
    }
   ],
   "source": [
    "sentences, pos_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 3,914개의 문장 샘플을 1개씩 불러온다.\n",
    "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 품사 태깅 정보들은 tag_info에 저장한다.\n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    pos_tags.append(list(tag_info)) # 각 샘플에서 품사 태깅 정보만 저장한다.\n",
    "    \n",
    "print(sentences[0])\n",
    "print(pos_tags[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a93c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', \"'re\", 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "['PRP', 'VBP', 'VBG', 'IN', 'NNS', 'IN', 'IN', 'NN', 'VBD', 'IN', 'NN', 'VBG', 'DT', 'JJ', 'NNS', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[8])\n",
    "print(pos_tags[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78a1fd",
   "metadata": {},
   "source": [
    "### 각 샘플의 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ce7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 271\n",
      "샘플의 평균 길이 : 25.722024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31460fd",
   "metadata": {},
   "source": [
    "### 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3345ab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 11388\n",
      "태깅 정보 집합의 크기 : 47\n"
     ]
    }
   ],
   "source": [
    "def tokenize(samples):\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(samples)\n",
    "  return tokenizer\n",
    "\n",
    "src_tokenizer = tokenize(sentences)\n",
    "tar_tokenizer = tokenize(pos_tags)\n",
    "\n",
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1487abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3], [31, 3746, 20, 177, 4, 5602, 2915, 1, 2, 2916, 637, 147, 3]]\n",
      "[[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9], [3, 3, 17, 1, 2, 3, 3, 8, 4, 3, 19, 1, 9]]\n"
     ]
    }
   ],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(pos_tags)\n",
    "\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecaad6",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0a1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "# X_train의 모든 샘플의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "# y_train의 모든 샘플의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd150c",
   "metadata": {},
   "source": [
    "### 훈련 데이터 와 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c864d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (3131, 150)\n",
      "훈련 샘플 레이블의 크기 : (3131, 150, 47)\n",
      "테스트 샘플 문장의 크기 : (783, 150)\n",
      "테스트 샘플 레이블의 크기 : (783, 150, 47)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)\n",
    "\n",
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78366b",
   "metadata": {},
   "source": [
    "### POS Tagger 모델 생성 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61cf7dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 07:30:17.369679: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-26 07:30:18.740651: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "25/25 [==============================] - 51s 1s/step - loss: 0.6236 - accuracy: 0.1159 - val_loss: 0.5067 - val_accuracy: 0.1602\n",
      "Epoch 2/6\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.4972 - accuracy: 0.1807 - val_loss: 0.4609 - val_accuracy: 0.3644\n",
      "Epoch 3/6\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.4451 - accuracy: 0.3875 - val_loss: 0.3300 - val_accuracy: 0.5018\n",
      "Epoch 4/6\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.2925 - accuracy: 0.5679 - val_loss: 0.1946 - val_accuracy: 0.7276\n",
      "Epoch 5/6\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.1631 - accuracy: 0.7808 - val_loss: 0.1067 - val_accuracy: 0.8593\n",
      "Epoch 6/6\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.0801 - accuracy: 0.9030 - val_loss: 0.0693 - val_accuracy: 0.8995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb96d023490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
    "model.compile(loss='categorical_crossentropy', optimizer= \"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=6,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef01b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 99ms/step - loss: 0.0693 - accuracy: 0.8995\n",
      "\n",
      " 테스트 정확도: 0.8995\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5602e3",
   "metadata": {},
   "source": [
    "### 실제값 과 예측값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ef2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "in               : IN      IN\n",
      "addition         : NN      NN\n",
      ",                : ,       ,\n",
      "buick            : NNP     NNP\n",
      "is               : VBZ     VBZ\n",
      "a                : DT      DT\n",
      "relatively       : RB      RB\n",
      "respected        : VBN     VBN\n",
      "nameplate        : NN      NN\n",
      "among            : IN      IN\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "card             : NN      NN\n",
      "holders          : NNS     NNS\n",
      ",                : ,       ,\n",
      "says             : VBZ     VBZ\n",
      "0                : -NONE-  -NONE-\n",
      "*t*-1            : -NONE-  -NONE-\n",
      "an               : DT      DT\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "spokeswoman      : NN      NN\n",
      ".                : .       .\n"
     ]
    }
   ],
   "source": [
    "index_to_word=src_tokenizer.index_word\n",
    "index_to_tag=tar_tokenizer.index_word\n",
    "\n",
    "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_tag[t].upper(), index_to_tag[pred].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6507b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59902d0f",
   "metadata": {},
   "source": [
    "## Subword Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee51d7",
   "metadata": {},
   "source": [
    "### BPE 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c07f769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Iteration 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
      "new merge: ('e', 's')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
      "new merge: ('es', 't')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
      "new merge: ('est', '</w>')\n",
      "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('l', 'o')\n",
      "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('lo', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('n', 'e')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('ne', 'w')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('new', 'est</w>')\n",
      "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('low', '</w>')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Iteration 10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
      "new merge: ('w', 'i')\n",
      "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
     ]
    }
   ],
   "source": [
    "import re, collections\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "num_merges = 10\n",
    "\n",
    "dictionary = {'l o w </w>' : 5,\n",
    "         'l o w e r </w>' : 2,\n",
    "         'n e w e s t </w>':6,\n",
    "         'w i d e s t </w>':3\n",
    "         }\n",
    "\n",
    "def get_stats(dictionary):\n",
    "    # 유니그램의 pair들의 빈도수를 카운트\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in dictionary.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    print('현재 pair들의 빈도수 :', dict(pairs))\n",
    "    return pairs\n",
    "\n",
    "def merge_dictionary(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "bpe_codes = {}\n",
    "bpe_codes_reverse = {}\n",
    "\n",
    "for i in range(num_merges):\n",
    "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
    "    pairs = get_stats(dictionary)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    dictionary = merge_dictionary(best, dictionary)\n",
    "\n",
    "    bpe_codes[best] = i\n",
    "    bpe_codes_reverse[best[0] + best[1]] = best\n",
    "\n",
    "    print(\"new merge: {}\".format(best))\n",
    "    print(\"dictionary: {}\".format(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5bf05fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('e', 's'): 0, ('es', 't'): 1, ('est', '</w>'): 2, ('l', 'o'): 3, ('lo', 'w'): 4, ('n', 'e'): 5, ('ne', 'w'): 6, ('new', 'est</w>'): 7, ('low', '</w>'): 8, ('w', 'i'): 9}\n"
     ]
    }
   ],
   "source": [
    "#merge 했던 기록 확인\n",
    "print(bpe_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf60f8",
   "metadata": {},
   "source": [
    "### BPE 알고리즘을 이용한 OOV 대처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a5f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def encode(orig):\n",
    "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
    "\n",
    "    word = tuple(orig) + ('</w>',)\n",
    "    display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
    "\n",
    "    pairs = get_pairs(word)    \n",
    "\n",
    "    if not pairs:\n",
    "        return orig\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
    "\n",
    "        print(\"bigrams in the word: {}\".format(pairs))\n",
    "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
    "        print(\"candidate for merging: {}\".format(bigram))\n",
    "        if bigram not in bpe_codes:\n",
    "            display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
    "            break\n",
    "        first, second = bigram\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            try:\n",
    "                j = word.index(first, i)\n",
    "                new_word.extend(word[i:j])\n",
    "                i = j\n",
    "            except:\n",
    "                new_word.extend(word[i:])\n",
    "                break\n",
    "\n",
    "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                new_word.append(first+second)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_word = tuple(new_word)\n",
    "        word = new_word\n",
    "        print(\"word after merging: {}\".format(word))\n",
    "        if len(word) == 1:\n",
    "            break\n",
    "        else:\n",
    "            pairs = get_pairs(word)\n",
    "\n",
    "    # 특별 토큰인 </w>는 출력하지 않는다.\n",
    "    if word[-1] == '</w>':\n",
    "        word = word[:-1]\n",
    "    elif word[-1].endswith('</w>'):\n",
    "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f628fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'k', 'i', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'k'), ('k', 'i'), ('l', 'o'), ('i', '</w>')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'k', 'i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('i', '</w>'), ('k', 'i'), ('lo', 'k')}\n",
      "candidate for merging: ('i', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('lo', 'k', 'i')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"loki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89ac6b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('w', 'e'), ('l', 'o'), ('s', 't'), ('e', 's'), ('o', 'w'), ('t', '</w>')}\n",
      "candidate for merging: ('e', 's')\n",
      "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('w', 'es'), ('l', 'o'), ('es', 't'), ('o', 'w'), ('t', '</w>')}\n",
      "candidate for merging: ('es', 't')\n",
      "word after merging: ('l', 'o', 'w', 'est', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 3:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('l', 'o'), ('est', '</w>'), ('w', 'est')}\n",
      "candidate for merging: ('est', '</w>')\n",
      "word after merging: ('l', 'o', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 4:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('o', 'w'), ('w', 'est</w>'), ('l', 'o')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'w', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 5:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('w', 'est</w>'), ('lo', 'w')}\n",
      "candidate for merging: ('lo', 'w')\n",
      "word after merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 6:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('low', 'est</w>')}\n",
      "candidate for merging: ('low', 'est</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('low', 'est')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e35e9fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('l', 'o', 'w', 'i', 'n', 'g', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('n', 'g'), ('i', 'n'), ('l', 'o'), ('w', 'i'), ('g', '</w>'), ('o', 'w')}\n",
      "candidate for merging: ('l', 'o')\n",
      "word after merging: ('lo', 'w', 'i', 'n', 'g', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 2:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('n', 'g'), ('lo', 'w'), ('i', 'n'), ('w', 'i'), ('g', '</w>')}\n",
      "candidate for merging: ('lo', 'w')\n",
      "word after merging: ('low', 'i', 'n', 'g', '</w>')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 3:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('n', 'g'), ('g', '</w>'), ('low', 'i'), ('i', 'n')}\n",
      "candidate for merging: ('n', 'g')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('low', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"lowing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cae9487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__word split into characters:__ <tt>('h', 'i', 'g', 'h', 'i', 'n', 'g', '</w>')</tt>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "__Iteration 1:__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams in the word: {('i', 'g'), ('n', 'g'), ('i', 'n'), ('g', 'h'), ('g', '</w>'), ('h', 'i')}\n",
      "candidate for merging: ('i', 'g')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "__Candidate not in BPE merges, algorithm stops.__"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('h', 'i', 'g', 'h', 'i', 'n', 'g')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"highing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4337919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46a55262",
   "metadata": {},
   "source": [
    "## IMDB 리뷰 토큰화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3245b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c0f24",
   "metadata": {},
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70baaf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        My family and I normally do not watch local mo...\n",
       "1        Believe it or not, this was at one time the wo...\n",
       "2        After some internet surfing, I found the \"Home...\n",
       "3        One of the most unheralded great works of anim...\n",
       "4        It was the Sixties, and anyone with long hair ...\n",
       "                               ...                        \n",
       "49995    the people who came up with this are SICK AND ...\n",
       "49996    The script is so so laughable... this in turn,...\n",
       "49997    \"So there's this bride, you see, and she gets ...\n",
       "49998    Your mind will not be satisfied by this nobud...\n",
       "49999    The chaser's war on everything is a weekly sho...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"./data/IMDb_Reviews.csv\")\n",
    "\n",
    "train_df = pd.read_csv('./data/IMDb_Reviews.csv')\n",
    "train_df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cea79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print('리뷰 개수 :',len(train_df)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7886942",
   "metadata": {},
   "source": [
    "### DataFrame 을 파일에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c253f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/imdb_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(train_df['review']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e1af6",
   "metadata": {},
   "source": [
    "### 센텐스피스로 단어 집합과 각 단어에 고유한 정수 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d116b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(170) LOG(INFO) Running command: --input=./data/imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\n",
      "sentencepiece_trainer.cc(75) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/imdb_review.txt\n",
      "  input_format: \n",
      "  model_prefix: imdb\n",
      "  model_type: BPE\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 9999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(330) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ./data/imdb_review.txt\n",
      "trainer_interface.cc(357) LOG(WARNING) Found too long line (10321 > 9999).\n",
      "trainer_interface.cc(359) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(360) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(386) LOG(INFO) Loaded all 49994 sentences\n",
      "trainer_interface.cc(392) LOG(INFO) Skipped 6 too long sentences.\n",
      "trainer_interface.cc(401) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(401) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(401) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(406) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(467) LOG(INFO) all chars count=65449658\n",
      "trainer_interface.cc(478) LOG(INFO) Done: 99.9552% characters are covered.\n",
      "trainer_interface.cc(488) LOG(INFO) Alphabet size=76\n",
      "trainer_interface.cc(489) LOG(INFO) Final character coverage=0.999552\n",
      "trainer_interface.cc(521) LOG(INFO) Done! preprocessed 49994 sentences.\n",
      "trainer_interface.cc(527) LOG(INFO) Tokenizing input sentences with whitespace: 49994\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 438648\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1557312 min_freq=370\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=384101 size=20 all=3611 active=1972 piece=en\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=220588 size=40 all=4932 active=3293 piece=om\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=158358 size=60 all=6355 active=4716 piece=ie\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=106638 size=80 all=7931 active=6292 piece=id\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=90444 size=100 all=9106 active=7467 piece=am\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=90105 min_freq=5571\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=65629 size=120 all=10550 active=2264 piece=ally\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=54246 size=140 all=11849 active=3563 piece=▁D\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=46634 size=160 all=13189 active=4903 piece=el\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=40539 size=180 all=15057 active=6771 piece=est\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=37018 size=200 all=16856 active=8570 piece=▁r\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=37013 min_freq=4976\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=33589 size=220 all=18215 active=2310 piece=▁just\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=30398 size=240 all=19801 active=3896 piece=▁un\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=27178 size=260 all=21138 active=5233 piece=▁get\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=24165 size=280 all=21984 active=6079 piece=▁bec\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=22036 size=300 all=22868 active=6962 piece=▁watch\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=22031 min_freq=3786\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=20573 size=320 all=24301 active=2568 piece=▁kn\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=19165 size=340 all=26044 active=4311 piece=▁pe\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=18034 size=360 all=26902 active=5169 piece=▁how\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=16799 size=380 all=27929 active=6196 piece=other\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=15869 size=400 all=29091 active=7358 piece=▁direct\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=15837 min_freq=2651\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=14689 size=420 all=30340 active=2692 piece=▁movies\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=13994 size=440 all=31418 active=3770 piece=ob\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=13210 size=460 all=32681 active=5033 piece=▁plot\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=12444 size=480 all=33133 active=5485 piece=ittle\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=11855 size=500 all=34396 active=6748 piece=ved\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=11779 min_freq=2011\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=11066 size=520 all=35371 active=2659 piece=▁br\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=10275 size=540 all=36482 active=3770 piece=▁scenes\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=9925 size=560 all=37358 active=4646 piece=▁again\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=9439 size=580 all=38292 active=5580 piece=▁19\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=8915 size=600 all=38978 active=6266 piece=reen\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=8909 min_freq=1638\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=8590 size=620 all=39970 active=2899 piece=▁fam\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=8189 size=640 all=40300 active=3229 piece=▁tra\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=7825 size=660 all=41154 active=4083 piece=oss\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=7505 size=680 all=41901 active=4830 piece=▁ter\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=7312 size=700 all=42577 active=5506 piece=hen\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=7306 min_freq=1375\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=6993 size=720 all=43326 active=2798 piece=▁around\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=6722 size=740 all=44141 active=3613 piece=most\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=6507 size=760 all=44801 active=4273 piece=ately\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=6324 size=780 all=45371 active=4843 piece=▁es\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=6120 size=800 all=46028 active=5500 piece=▁tell\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=6116 min_freq=1212\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5985 size=820 all=46369 active=2634 piece=▁come\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5811 size=840 all=46810 active=3075 piece=▁shot\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5639 size=860 all=47369 active=3634 piece=ouse\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5430 size=880 all=48019 active=4284 piece=▁An\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5199 size=900 all=48725 active=4990 piece=▁ext\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=5190 min_freq=1094\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5048 size=920 all=49357 active=3049 piece=als\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4903 size=940 all=50618 active=4310 piece=▁Be\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4819 size=960 all=50968 active=4660 piece=▁believe\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4677 size=980 all=51700 active=5392 piece=ommend\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4568 size=1000 all=52297 active=5989 piece=▁boy\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=4568 min_freq=961\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4487 size=1020 all=52880 active=3190 piece=ray\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4390 size=1040 all=53357 active=3667 piece=▁money\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4299 size=1060 all=54338 active=4648 piece=▁For\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4191 size=1080 all=54923 active=5233 piece=ues\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4078 size=1100 all=55276 active=5586 piece=udget\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=4070 min_freq=872\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4013 size=1120 all=55852 active=3330 piece=cing\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3934 size=1140 all=56599 active=4077 piece=▁beautiful\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3813 size=1160 all=57309 active=4786 piece=▁home\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3755 size=1180 all=57728 active=5205 piece=▁once\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3650 size=1200 all=58426 active=5903 piece=▁open\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=3648 min_freq=784\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3573 size=1220 all=59047 active=3534 piece=▁exp\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3490 size=1240 all=59620 active=4107 piece=▁along\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3408 size=1260 all=59981 active=4468 piece=▁dra\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3329 size=1280 all=60631 active=5118 piece=▁exam\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3280 size=1300 all=61062 active=5549 piece=med\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=3279 min_freq=719\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3220 size=1320 all=61410 active=3340 piece=▁hero\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3157 size=1340 all=61958 active=3888 piece=▁instead\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3045 size=1360 all=62708 active=4638 piece=▁doing\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3008 size=1380 all=63181 active=5111 piece=reme\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2941 size=1400 all=63666 active=5596 piece=▁cor\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=2937 min_freq=664\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2884 size=1420 all=64123 active=3614 piece=▁develop\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2818 size=1440 all=64653 active=4144 piece=▁stars\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2755 size=1460 all=65239 active=4730 piece=ccess\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2690 size=1480 all=65725 active=5216 piece=▁seemed\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2647 size=1500 all=66045 active=5536 piece=▁several\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=2644 min_freq=619\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2597 size=1520 all=66478 active=3736 piece=▁adm\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2549 size=1540 all=66932 active=4190 piece=▁although\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2491 size=1560 all=67428 active=4686 piece=▁self\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2440 size=1580 all=67834 active=5092 piece=▁works\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2399 size=1600 all=68242 active=5500 piece=▁sn\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=2399 min_freq=577\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2370 size=1620 all=68586 active=3709 piece=▁sat\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2324 size=1640 all=69187 active=4310 piece=ern\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2291 size=1660 all=69602 active=4725 piece=▁cult\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2256 size=1680 all=69899 active=5022 piece=▁fig\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2224 size=1700 all=70385 active=5508 piece=▁cost\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=2224 min_freq=543\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2192 size=1720 all=70846 active=3967 piece=▁happens\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2151 size=1740 all=71385 active=4506 piece=▁fore\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2108 size=1760 all=71863 active=4984 piece=gs\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2077 size=1780 all=72390 active=5511 piece=ering\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2047 size=1800 all=72864 active=5985 piece=▁cheap\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=2046 min_freq=509\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2019 size=1820 all=73259 active=4027 piece=▁move\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1985 size=1840 all=73555 active=4323 piece=dy\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1968 size=1860 all=74249 active=5017 piece=▁musical\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1940 size=1880 all=74981 active=5749 piece=mp\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1914 size=1900 all=75562 active=6330 piece=But\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1909 min_freq=475\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1882 size=1920 all=75761 active=3970 piece=▁foc\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1860 size=1940 all=75996 active=4205 piece=▁opinion\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1841 size=1960 all=76442 active=4651 piece=▁possible\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1812 size=1980 all=76904 active=5113 piece=aim\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1797 size=2000 all=77293 active=5502 piece=▁usual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1796 min_freq=452\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1779 size=2020 all=77459 active=4030 piece=▁knew\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1745 size=2040 all=77968 active=4539 piece=!\"\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1716 size=2060 all=78438 active=5009 piece=▁ten\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1700 size=2080 all=78981 active=5552 piece=▁Ne\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1676 size=2100 all=79331 active=5902 piece=▁tells\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1675 min_freq=427\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1648 size=2120 all=79667 active=4303 piece=light\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1624 size=2140 all=80056 active=4692 piece=▁sets\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1602 size=2160 all=80402 active=5038 piece=▁upon\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1581 size=2180 all=80727 active=5363 piece=▁clearly\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1562 size=2200 all=80912 active=5548 piece=▁feature\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1560 min_freq=409\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1542 size=2220 all=81259 active=4391 piece=▁showing\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1522 size=2240 all=81653 active=4785 piece=ltim\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1503 size=2260 all=82061 active=5193 piece=EA\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1491 size=2280 all=82516 active=5648 piece=▁feels\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1473 size=2300 all=82836 active=5968 piece=bs\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1473 min_freq=386\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1448 size=2320 all=83040 active=4278 piece=▁tre\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1432 size=2340 all=83288 active=4526 piece=▁*\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1408 size=2360 all=83828 active=5066 piece=▁begins\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1397 size=2380 all=84097 active=5335 piece=▁background\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1372 size=2400 all=84332 active=5570 piece=esome\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1372 min_freq=370\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1358 size=2420 all=84823 active=4701 piece=lfriend\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1337 size=2440 all=85169 active=5047 piece=▁From\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1321 size=2460 all=85531 active=5409 piece=▁tast\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1307 size=2480 all=85808 active=5686 piece=ee\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1295 size=2500 all=86179 active=6057 piece=▁King\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1294 min_freq=352\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1278 size=2520 all=86653 active=4777 piece=▁prop\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1261 size=2540 all=87066 active=5190 piece=over\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1250 size=2560 all=87446 active=5570 piece=▁quickly\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1240 size=2580 all=87767 active=5891 piece=▁oper\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1227 size=2600 all=88178 active=6302 piece=acy\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1227 min_freq=337\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1214 size=2620 all=88552 active=4740 piece=▁Japanese\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1201 size=2640 all=88940 active=5128 piece=ze\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1189 size=2660 all=89189 active=5377 piece=ana\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1178 size=2680 all=89606 active=5794 piece=▁collect\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1165 size=2700 all=89868 active=6056 piece=▁spent\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1165 min_freq=324\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1151 size=2720 all=90214 active=4840 piece=▁Lu\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1138 size=2740 all=90584 active=5209 piece=▁attempts\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1121 size=2760 all=91034 active=5659 piece=▁Bra\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1109 size=2780 all=91300 active=5925 piece=▁ended\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1099 size=2800 all=91577 active=6202 piece=▁fighting\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1096 min_freq=310\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1088 size=2820 all=92053 active=5054 piece=▁World\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1078 size=2840 all=92347 active=5348 piece=cent\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1066 size=2860 all=92609 active=5610 piece=▁Pro\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1057 size=2880 all=92918 active=5919 piece=ha\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1046 size=2900 all=93183 active=6184 piece=umes\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1046 min_freq=298\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1037 size=2920 all=93452 active=4913 piece=▁decides\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1028 size=2940 all=93721 active=5182 piece=berg\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1019 size=2960 all=94051 active=5512 piece=▁explo\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1008 size=2980 all=94300 active=5761 piece=ashion\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=999 size=3000 all=94880 active=6341 piece=uster\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=998 min_freq=284\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=984 size=3020 all=95216 active=5061 piece=idden\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=972 size=3040 all=95522 active=5367 piece=▁longer\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=964 size=3060 all=95846 active=5691 piece=▁company\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=953 size=3080 all=96192 active=6037 piece=000\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=944 size=3100 all=96622 active=6467 piece=▁breat\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=944 min_freq=274\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=939 size=3120 all=96746 active=4949 piece=▁changed\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=928 size=3140 all=96853 active=5056 piece=▁Love\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=915 size=3160 all=97152 active=5355 piece=mon\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=910 size=3180 all=97433 active=5636 piece=▁failed\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=902 size=3200 all=97574 active=5777 piece=▁trash\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=901 min_freq=268\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=894 size=3220 all=97854 active=5153 piece=▁accur\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=887 size=3240 all=98314 active=5613 piece=▁bomb\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=878 size=3260 all=98614 active=5913 piece=▁Dra\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=872 size=3280 all=98800 active=6099 piece=▁runs\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=864 size=3300 all=99075 active=6374 piece=▁Ber\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=864 min_freq=258\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=857 size=3320 all=99425 active=5265 piece=lessly\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=848 size=3340 all=99866 active=5706 piece=▁smart\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=841 size=3360 all=100282 active=6122 piece=opher\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=833 size=3380 all=100473 active=6313 piece=▁normal\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=826 size=3400 all=100654 active=6494 piece=\".<\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=826 min_freq=249\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=819 size=3420 all=100794 active=5158 piece=▁suppose\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=813 size=3440 all=100946 active=5310 piece=▁jo\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=806 size=3460 all=101157 active=5521 piece=▁demon\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=799 size=3480 all=101415 active=5779 piece=▁tone\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=793 size=3500 all=101659 active=6023 piece=▁Ant\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=793 min_freq=242\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=787 size=3520 all=101992 active=5384 piece=arsh\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=780 size=3540 all=102176 active=5568 piece=field\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=773 size=3560 all=102533 active=5925 piece=▁ur\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=767 size=3580 all=102719 active=6111 piece=▁makers\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=760 size=3600 all=103008 active=6400 piece=CH\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=759 min_freq=234\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=754 size=3620 all=103269 active=5348 piece=▁element\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=748 size=3640 all=103402 active=5481 piece=▁current\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=742 size=3660 all=103707 active=5786 piece=▁drive\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=733 size=3680 all=104052 active=6131 piece=▁Yet\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=728 size=3700 all=104235 active=6314 piece=▁students\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=727 min_freq=228\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=722 size=3720 all=104630 active=5607 piece=▁irrit\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=714 size=3740 all=104878 active=5855 piece=▁trag\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=710 size=3760 all=105039 active=6016 piece=▁drawn\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=704 size=3780 all=105222 active=6199 piece=▁confused\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=699 size=3800 all=105520 active=6497 piece=▁hospital\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=698 min_freq=222\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=692 size=3820 all=105761 active=5514 piece=▁Kelly\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=687 size=3840 all=106078 active=5831 piece=▁symbol\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=682 size=3860 all=106379 active=6132 piece=▁joy\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=676 size=3880 all=106592 active=6345 piece=azz\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=672 size=3900 all=106958 active=6711 piece=▁bi\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=672 min_freq=216\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=669 size=3920 all=107164 active=5538 piece=▁market\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=664 size=3940 all=107326 active=5699 piece=▁pen\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=660 size=3960 all=107556 active=5929 piece=▁mat\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=657 size=3980 all=107897 active=6270 piece=▁fort\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=652 size=4000 all=108176 active=6549 piece=she\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=652 min_freq=210\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=649 size=4020 all=108386 active=5592 piece=ishes\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=646 size=4040 all=108572 active=5778 piece=▁member\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=641 size=4060 all=108880 active=6086 piece=odies\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=636 size=4080 all=109044 active=6250 piece=ffe\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=632 size=4100 all=109338 active=6544 piece=▁rated\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=632 min_freq=205\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=626 size=4120 all=109552 active=5681 piece=▁began\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=620 size=4140 all=109679 active=5808 piece=▁realized\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=615 size=4160 all=109896 active=6025 piece=▁depart\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=611 size=4180 all=110267 active=6396 piece=▁artistic\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=607 size=4200 all=110534 active=6663 piece=▁energy\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=607 min_freq=200\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=603 size=4220 all=110795 active=5788 piece=▁necessary\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=599 size=4240 all=111094 active=6087 piece=▁intriguing\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=596 size=4260 all=111301 active=6294 piece=▁deserve\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=590 size=4280 all=111377 active=6370 piece=▁intelligence\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=587 size=4300 all=111611 active=6604 piece=entious\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=587 min_freq=195\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=583 size=4320 all=111811 active=5773 piece=▁Cam\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=580 size=4340 all=112034 active=5996 piece=▁elect\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=575 size=4360 all=112355 active=6317 piece=bered\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=570 size=4380 all=112667 active=6629 piece=ording\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=567 size=4400 all=112885 active=6847 piece=▁surreal\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=566 min_freq=190\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=563 size=4420 all=113186 active=5942 piece=▁issue\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=559 size=4440 all=113400 active=6156 piece=hered\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=557 size=4460 all=113502 active=6258 piece=▁learned\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=553 size=4480 all=113778 active=6534 piece=▁months\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=549 size=4500 all=113949 active=6705 piece=▁Danny\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=549 min_freq=185\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=546 size=4520 all=114169 active=5918 piece=▁mental\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=542 size=4540 all=114402 active=6151 piece=▁Ter\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=539 size=4560 all=114573 active=6322 piece=▁efforts\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=535 size=4580 all=114818 active=6567 piece=▁floor\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=532 size=4600 all=114982 active=6731 piece=▁rubbish\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=531 min_freq=182\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=529 size=4620 all=115141 active=5908 piece=▁survive\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=526 size=4640 all=115303 active=6070 piece=▁hidden\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=522 size=4660 all=115544 active=6311 piece=aren\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=520 size=4680 all=115796 active=6563 piece=▁mixed\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=516 size=4700 all=115930 active=6697 piece=they\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=516 min_freq=177\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=513 size=4720 all=116053 active=5918 piece=▁text\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=510 size=4740 all=116265 active=6130 piece=elle\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=507 size=4760 all=116412 active=6277 piece=▁revealed\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=503 size=4780 all=116801 active=6666 piece=▁window\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=500 size=4800 all=116988 active=6853 piece=▁ing\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=500 min_freq=173\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=497 size=4820 all=117337 active=6189 piece=▁sed\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=495 size=4840 all=117559 active=6411 piece=▁environ\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=492 size=4860 all=117823 active=6675 piece=▁pretentious\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=489 size=4880 all=118019 active=6871 piece=▁teenagers\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=486 size=4900 all=118162 active=7014 piece=▁fra\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=486 min_freq=168\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=484 size=4920 all=118371 active=6105 piece=▁miser\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: imdb.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: imdb.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=./data/imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafb7de",
   "metadata": {},
   "source": [
    "### 단어 집합의 크기를 확인하기 위해서 imdb.vocab 파일을 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d96155d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>▁result</td>\n",
       "      <td>-1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>▁happen</td>\n",
       "      <td>-941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>▁Europe</td>\n",
       "      <td>-2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>▁Am</td>\n",
       "      <td>-1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>▁remarkable</td>\n",
       "      <td>-4408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>▁50</td>\n",
       "      <td>-3793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>▁sed</td>\n",
       "      <td>-4819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>▁product</td>\n",
       "      <td>-3193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>▁troub</td>\n",
       "      <td>-4814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>▁dam</td>\n",
       "      <td>-2577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0     1\n",
       "1812      ▁result -1809\n",
       "944       ▁happen  -941\n",
       "2968      ▁Europe -2965\n",
       "1981          ▁Am -1978\n",
       "4411  ▁remarkable -4408\n",
       "3796          ▁50 -3793\n",
       "4822         ▁sed -4819\n",
       "3196     ▁product -3193\n",
       "4817       ▁troub -4814\n",
       "2580         ▁dam -2577"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('imdb.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902ceaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d4e44",
   "metadata": {},
   "source": [
    "### model 파일을 로드하여 단어 시퀀스를 정수 시퀀스로 바꾸는 인코딩 작업이나 반대로 변환하는 디코딩 작업을 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15f58ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"imdb.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d26c84",
   "metadata": {},
   "source": [
    "### 여러가지 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ab10f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't at all think of it this way.\n",
      "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
      "[41, 623, 4950, 4926, 138, 169, 378, 30, 58, 73, 413, 4945]\n",
      "\n",
      "I have waited a long time for someone to film\n",
      "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
      "[41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "  \"I didn't at all think of it this way.\",\n",
    "  \"I have waited a long time for someone to film\"\n",
    "]\n",
    "for line in lines:\n",
    "  print(line)\n",
    "  print(sp.encode_as_pieces(line))\n",
    "  print(sp.encode_as_ids(line))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f59d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b23a79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁character'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.IdToPiece(430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987a6653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.PieceToId('▁character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e69771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have waited a long time for someone to film'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds([41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e7a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have waited a long time for someone to film'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodePieces(['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46b55a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
      "[41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode('I have waited a long time for someone to film', out_type=str))\n",
    "print(sp.encode('I have waited a long time for someone to film', out_type=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953ed92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02c2e300",
   "metadata": {},
   "source": [
    "## 네이버 영화 리뷰 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a785b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aede9b",
   "metadata": {},
   "source": [
    "### 네이버 영화 리뷰 데이터를 다운로드하여 데이터프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3463ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"./data/ratings.txt\")\n",
    "naver_df = pd.read_table('./data/ratings.txt')\n",
    "naver_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d0e74",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc2674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 개수 : 200000\n"
     ]
    }
   ],
   "source": [
    "print('리뷰 개수 :',len(naver_df)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb504b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#네이버 영화 리뷰 데이터의 경우 Null 값이 존재하므로 이를 제거한 후에 수행합니다.\n",
    "print(naver_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec10111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "리뷰 개수 : 199992\n"
     ]
    }
   ],
   "source": [
    "naver_df = naver_df.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(naver_df.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "print('리뷰 개수 :',len(naver_df)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1eb24",
   "metadata": {},
   "source": [
    "### 199,992개의 샘플을 naver_review.txt 파일에 저장한 후에 센텐스피스를 통해 단어 집합을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e2f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b4ebd",
   "metadata": {},
   "source": [
    "### vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f441f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(170) LOG(INFO) Running command: --input=naver_review.txt --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_length=9999\n",
      "sentencepiece_trainer.cc(75) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: naver_review.txt\n",
      "  input_format: \n",
      "  model_prefix: naver\n",
      "  model_type: BPE\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 9999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(330) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: naver_review.txt\n",
      "trainer_interface.cc(386) LOG(INFO) Loaded all 199992 sentences\n",
      "trainer_interface.cc(401) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(401) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(401) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(406) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(467) LOG(INFO) all chars count=7242982\n",
      "trainer_interface.cc(478) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(488) LOG(INFO) Alphabet size=1725\n",
      "trainer_interface.cc(489) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(521) LOG(INFO) Done! preprocessed 199992 sentences.\n",
      "trainer_interface.cc(527) LOG(INFO) Tokenizing input sentences with whitespace: 199992\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 449380\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=97156 min_freq=100\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=14530 size=20 all=124348 active=11716 piece=▁어\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=11891 size=40 all=129289 active=16657 piece=▁정말\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=8425 size=60 all=133221 active=20589 piece=▁생\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=7007 size=80 all=137613 active=24981 piece=드라마\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=5651 size=100 all=141799 active=29167 piece=▁보고\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=5550 min_freq=84\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4812 size=120 all=145059 active=10278 piece=▁아니\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=4300 size=140 all=147973 active=13192 piece=적인\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3782 size=160 all=150509 active=15728 piece=^^\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3533 size=180 all=153307 active=18526 piece=▁처\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=3192 size=200 all=155981 active=21200 piece=지는\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=3188 min_freq=75\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2945 size=220 all=158892 active=10451 piece=▁처음\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2751 size=240 all=162104 active=13663 piece=인데\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2568 size=260 all=165344 active=16903 piece=▁이해\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2400 size=280 all=168524 active=20083 piece=▁화\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2251 size=300 all=170103 active=21662 piece=▁당\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=2249 min_freq=67\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=2077 size=320 all=172592 active=10936 piece=▁발\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1941 size=340 all=175084 active=13427 piece=것도\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1856 size=360 all=177590 active=15933 piece=▁무슨\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1756 size=380 all=180110 active=18453 piece=▁아깝다\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1681 size=400 all=182285 active=20628 piece=▁리\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1680 min_freq=61\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1629 size=420 all=184123 active=10856 piece=▁스릴\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1560 size=440 all=186113 active=12846 piece=재밌\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1484 size=460 all=188667 active=15400 piece=▁극장\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1430 size=480 all=190368 active=17101 piece=처럼\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1367 size=500 all=192609 active=19342 piece=▁근\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1361 min_freq=57\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1313 size=520 all=194421 active=11407 piece=떨어\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1249 size=540 all=196182 active=13168 piece=▁캐릭터\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1202 size=560 all=198172 active=15158 piece=▁독\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1174 size=580 all=200926 active=17912 piece=이랑\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1142 size=600 all=203281 active=20267 piece=▁영화에\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=1141 min_freq=53\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1113 size=620 all=205463 active=12323 piece=기는\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1071 size=640 all=207929 active=14789 piece=▁싸\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1044 size=660 all=210014 active=16874 piece=▁조금\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=1012 size=680 all=212262 active=19122 piece=하면서\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=979 size=700 all=214255 active=21115 piece=▁네\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=979 min_freq=49\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=951 size=720 all=215942 active=12348 piece=▁알바\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=924 size=740 all=217742 active=14148 piece=▁감독이\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=893 size=760 all=218971 active=15377 piece=▁복\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=867 size=780 all=220584 active=16990 piece=▁살아\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=852 size=800 all=222637 active=19043 piece=▁아직도\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=850 min_freq=46\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=830 size=820 all=223807 active=12280 piece=▁글\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=815 size=840 all=225048 active=13521 piece=▁친구\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=791 size=860 all=226687 active=15160 piece=▁변\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=775 size=880 all=228073 active=16546 piece=▁자신\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=760 size=900 all=229401 active=17874 piece=▁인상\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=759 min_freq=45\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=742 size=920 all=230810 active=12857 piece=▁청\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=729 size=940 all=232270 active=14317 piece=▁둘\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=714 size=960 all=233554 active=15601 piece=놓고\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=703 size=980 all=234703 active=16750 piece=다면\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=684 size=1000 all=235917 active=17964 piece=▁혼\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=684 min_freq=43\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=672 size=1020 all=237248 active=13086 piece=▁애니메이션\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=660 size=1040 all=238777 active=14615 piece=주의\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=640 size=1060 all=240624 active=16462 piece=▁백\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=624 size=1080 all=242078 active=17916 piece=당히\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=613 size=1100 all=243582 active=19420 piece=▁같이\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=613 min_freq=41\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=599 size=1120 all=245031 active=13598 piece=▁색\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=585 size=1140 all=246151 active=14718 piece=▁순수\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=572 size=1160 all=247528 active=16095 piece=▁비슷\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=561 size=1180 all=248947 active=17514 piece=자체\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=551 size=1200 all=250592 active=19159 piece=▁프로\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=550 min_freq=39\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=539 size=1220 all=252024 active=13898 piece=▁비교\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=524 size=1240 all=253463 active=15337 piece=▁벌\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=513 size=1260 all=254873 active=16747 piece=▁있을\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=507 size=1280 all=256062 active=17936 piece=보기\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=498 size=1300 all=257875 active=19748 piece=▁화려\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=498 min_freq=37\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=487 size=1320 all=259149 active=14140 piece=그런\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=477 size=1340 all=260384 active=15375 piece=었고\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=471 size=1360 all=261670 active=16661 piece=▁보니\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=466 size=1380 all=263235 active=18226 piece=▁두번\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=460 size=1400 all=264814 active=19805 piece=이팅\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=460 min_freq=36\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=451 size=1420 all=266024 active=14414 piece=▁아쉽다\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=443 size=1440 all=267460 active=15850 piece=▁진정한\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=434 size=1460 all=268300 active=16690 piece=▁굉장히\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=428 size=1480 all=269350 active=17740 piece=▁나와서\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=420 size=1500 all=270501 active=18891 piece=▁나의\n",
      "bpe_model_trainer.cc(166) LOG(INFO) Updating active symbols. max_freq=420 min_freq=35\n",
      "bpe_model_trainer.cc(257) LOG(INFO) Added: freq=412 size=1520 all=272021 active=15017 piece"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=naver_review.txt --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')\n",
    "#vocab 생성이 완료되면 naver.model, naver.vocab 파일 두개가 생성 됩니다. .vocab 에서 학습된 subwords를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df492a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁이</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁아</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>▁그</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  <unk>  0\n",
       "1    <s>  0\n",
       "2   </s>  0\n",
       "3     ..  0\n",
       "4     영화 -1\n",
       "5    ▁영화 -2\n",
       "6     ▁이 -3\n",
       "7     ▁아 -4\n",
       "8    ... -5\n",
       "9     ▁그 -6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('naver.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list[:10]\n",
    "\n",
    "#Vocabulary 에는 unknown, 문장의 시작, 문장의 끝을 의미하는 special token이 0, 1, 2에 사용되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162f4c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>쿡</td>\n",
       "      <td>-4332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>▁달</td>\n",
       "      <td>-590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>ad</td>\n",
       "      <td>-3039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>이트</td>\n",
       "      <td>-1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>죤</td>\n",
       "      <td>-4392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>▁관</td>\n",
       "      <td>-265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>▁최악의</td>\n",
       "      <td>-586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>다운</td>\n",
       "      <td>-2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>횟</td>\n",
       "      <td>-4817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>으며</td>\n",
       "      <td>-1705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "4335     쿡 -4332\n",
       "593     ▁달  -590\n",
       "3042    ad -3039\n",
       "1537    이트 -1534\n",
       "4395     죤 -4392\n",
       "268     ▁관  -265\n",
       "589   ▁최악의  -586\n",
       "2257    다운 -2254\n",
       "4820     횟 -4817\n",
       "1708    으며 -1705"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb4ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aec484c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = \"naver.model\"\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df6da2",
   "metadata": {},
   "source": [
    "### 문장 서브워드 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922572bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뭐 이딴 것도 영화냐.\n",
      "['▁뭐', '▁이딴', '▁것도', '▁영화냐', '.']\n",
      "[132, 966, 1296, 2590, 3276]\n",
      "\n",
      "진짜 최고의 영화입니다 ㅋㅋ\n",
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "[54, 200, 821, 85]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\n",
    "  \"뭐 이딴 것도 영화냐.\",\n",
    "  \"진짜 최고의 영화입니다 ㅋㅋ\",\n",
    "]\n",
    "for line in lines:\n",
    "  print(line)\n",
    "  print(sp.encode_as_pieces(line))\n",
    "  print(sp.encode_as_ids(line))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ba990",
   "metadata": {},
   "source": [
    "### 토큰화 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd20f800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5032427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'영화'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.IdToPiece(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "401ce3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.PieceToId('영화')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41bda5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'진짜 최고의 영화입니다 ᄏᄏ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds([54, 200, 821, 85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f28db2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'진짜 최고의 영화입니다 ᄏᄏ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodePieces(['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fa5001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
      "[54, 200, 821, 85]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode('진짜 최고의 영화입니다 ㅋㅋ', out_type=str))\n",
    "print(sp.encode('진짜 최고의 영화입니다 ㅋㅋ', out_type=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe3cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a8dc41",
   "metadata": {},
   "source": [
    "## SubwordTextEncoder를 이용한 IMDB 리뷰 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290abfad",
   "metadata": {},
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f0326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        My family and I normally do not watch local mo...\n",
       "1        Believe it or not, this was at one time the wo...\n",
       "2        After some internet surfing, I found the \"Home...\n",
       "3        One of the most unheralded great works of anim...\n",
       "4        It was the Sixties, and anyone with long hair ...\n",
       "                               ...                        \n",
       "49995    the people who came up with this are SICK AND ...\n",
       "49996    The script is so so laughable... this in turn,...\n",
       "49997    \"So there's this bride, you see, and she gets ...\n",
       "49998    Your mind will not be satisfied by this nobud...\n",
       "49999    The chaser's war on everything is a weekly sho...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")\n",
    "\n",
    "train_df = pd.read_csv('IMDb_Reviews.csv')\n",
    "\n",
    "train_df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cd79b",
   "metadata": {},
   "source": [
    "### 서브워드들로 이루어진 단어 집합(Vocabulary)를 생성하고, 각 서브워드에 고유한 정수를 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39d5b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(train_df['review'], target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d788995",
   "metadata": {},
   "source": [
    "### 10개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a402793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 't_', 'as_', 'with_', 'for_', '.<', 'on_', 'but_', 'movie_', 'are_', ' (', 'have_', 'his_', 'film_', 'not_', 'be_', 'you_', 'ing_', ' \"', 'ed_', 'it', 'd_', 'an_', 'at_', 'by_', 'he_', 'one_', 'who_', 'from_', 'y_', 'or_', 'e_', 'like_', 'all_', '\" ', 'they_', 'so_', 'just_', 'has_', ') ', 'about_', 'her_', 'out_', 'This_', 'some_', 'movie', 'ly_', 'film', 'very_', 'more_', 'It_', 'what_', 'would_', 'when_', 'if_', 'good_', 'up_', 'which_', 'their_', 'only_', 'even_', 'my_', 'really_', 'had_', 'can_', 'no_', 'were_', 'see_', '? ', 'she_', 'than_', '! ', 'there_', 'been_', 'get_', 'into_', 'will_', ' - ', 'much_', 'n_', 'because_', 'ing']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.subwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44f4e76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty bad PRC cheapie which I rarely bother to watch over again, and it's no wonder -- it's slow and creaky and dull as a butter knife. Mad doctor George Zucco is at it again, turning a dimwitted farmhand in overalls (Glenn Strange) into a wolf-man. Unfortunately, the makeup is virtually non-existent, consisting only of a beard and dimestore fangs for the most part. If it were not for Zucco and Strange's presence, along with the cute Anne Nagel, this would be completely unwatchable. Strange, who would go on to play Frankenstein's monster for Unuiversal in two years, does a Lenny impression from \"Of Mice and Men\", it seems.<br /><br />*1/2 (of Four)\n"
     ]
    }
   ],
   "source": [
    "print(train_df['review'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2829e5",
   "metadata": {},
   "source": [
    "### encode()를 통해서 입력한 데이터에 대해서 정수 인코딩을 수행한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fa5f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question: [1590, 4162, 132, 7107, 1892, 2983, 578, 76, 12, 4632, 3422, 7, 160, 175, 372, 2, 5, 39, 8051, 8, 84, 2652, 497, 39, 8051, 8, 1374, 5, 3461, 2012, 48, 5, 2263, 21, 4, 2992, 127, 4729, 711, 3, 1391, 8044, 3557, 1277, 8102, 2154, 5681, 9, 42, 15, 372, 2, 3773, 4, 3502, 2308, 467, 4890, 1503, 11, 3347, 1419, 8127, 29, 5539, 98, 6099, 58, 94, 4, 1388, 4230, 8057, 213, 3, 1966, 2, 1, 6700, 8044, 9, 7069, 716, 8057, 6600, 2, 4102, 36, 78, 6, 4, 1865, 40, 5, 3502, 1043, 1645, 8044, 1000, 1813, 23, 1, 105, 1128, 3, 156, 15, 85, 33, 23, 8102, 2154, 5681, 5, 6099, 8051, 8, 7271, 1055, 2, 534, 22, 1, 3046, 5214, 810, 634, 8120, 2, 14, 71, 34, 436, 3311, 5447, 783, 3, 6099, 2, 46, 71, 193, 25, 7, 428, 2274, 2260, 6487, 8051, 8, 2149, 23, 1138, 4117, 6023, 163, 11, 148, 735, 2, 164, 4, 5277, 921, 3395, 1262, 37, 639, 1349, 349, 5, 2460, 328, 15, 5349, 8127, 24, 10, 16, 10, 17, 8054, 8061, 8059, 8062, 29, 6, 6607, 8126, 8053]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized sample question: {}'.format(tokenizer.encode(train_df['review'][20])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5327ec8",
   "metadata": {},
   "source": [
    "### 임의로 선택한 짧은 문장에 대해서 정수 인코딩 결과를 확인하고 이를 다시 역으로 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ff31445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n",
      "기존 문장: It's mind-blowing to me that this film was even made.\n"
     ]
    }
   ],
   "source": [
    "# train_df에 존재하는 문장 중 일부를 발췌\n",
    "sample_string = \"It's mind-blowing to me that this film was even made.\"\n",
    "\n",
    "# 인코딩한 결과를 tokenized_string에 저장\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# 이를 다시 디코딩\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb56f1",
   "metadata": {},
   "source": [
    "### 단어 사전의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b649a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기(Vocab size) : 8268\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기(Vocab size) :', tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "685433b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ----> It\n",
      "8051 ----> '\n",
      "8 ----> s \n",
      "910 ----> mind\n",
      "8057 ----> -\n",
      "2169 ----> blow\n",
      "36 ----> ing \n",
      "7 ----> to \n",
      "103 ----> me \n",
      "13 ----> that \n",
      "14 ----> this \n",
      "32 ----> film \n",
      "18 ----> was \n",
      "79 ----> even \n",
      "681 ----> made\n",
      "8058 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af935a55",
   "metadata": {},
   "source": [
    "### 이전 문장에 글자 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43a9a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n",
      "기존 문장: It's mind-blowing to me that this film was evenxyz made.\n"
     ]
    }
   ],
   "source": [
    "#실습한 문장에 even 뒤에 임의로 xyz 추가\n",
    "sample_string = \"It's mind-blowing to me that this film was evenxyz made.\"\n",
    "\n",
    "# 인코딩한 결과를 tokenized_string에 저장\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# 이를 다시 디코딩\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c4efc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ----> It\n",
      "8051 ----> '\n",
      "8 ----> s \n",
      "910 ----> mind\n",
      "8057 ----> -\n",
      "2169 ----> blow\n",
      "36 ----> ing \n",
      "7 ----> to \n",
      "103 ----> me \n",
      "13 ----> that \n",
      "14 ----> this \n",
      "32 ----> film \n",
      "18 ----> was \n",
      "7974 ----> even\n",
      "8132 ----> x\n",
      "8133 ----> y\n",
      "997 ----> z \n",
      "681 ----> made\n",
      "8058 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140427df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6293ff",
   "metadata": {},
   "source": [
    "## 네이버 영화 리뷰 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100217f",
   "metadata": {},
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7268a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    5\n",
      "label       0\n",
      "dtype: int64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "\n",
    "train_data = pd.read_table('ratings_train.txt')\n",
    "\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f88651",
   "metadata": {},
   "source": [
    "### tfds.features.text.SubwordTextEncoder.build_from_corpus의 인자로 네이버 영화 리뷰 데이터를 넣어서\n",
    "### 서브워드들로 이루어진 단어 집합(Vocabulary)를 생성하고, 각 서브워드에 고유한 정수를 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e39bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    train_data['document'], target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e0ec5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['. ', '..', '영화', '이_', '...', '의_', '는_', '도_', '다', ', ', '을_', '고_', '은_', '가_', '에_', '.. ', '한_', '너무_', '정말_', '를_', '고', '게_', '영화_', '지', '... ', '진짜_', '이', '다_', '요', '만_', '? ', '과_', '나', '가', '서_', '지_', '로_', '으로_', '아', '어', '....', '음', '한', '수_', '와_', '도', '네', '그냥_', '나_', '더_', '왜_', '이런_', '면_', '기', '하고_', '보고_', '하는_', '서', '좀_', '리', '자', '스', '안', '! ', '에서_', '영화를_', '미', 'ㅋㅋ', '네요', '시', '주', '라', '는', '오', '없는_', '에', '해', '사', '!!', '영화는_', '마', '잘_', '수', '영화가_', '만', '본_', '로', '그_', '지만_', '대', '은', '비', '의', '일', '개', '있는_', '없다', '함', '구', '하']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.subwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c239f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question: [669, 4700, 17, 1749, 8, 96, 131, 1, 48, 2239, 4, 7466, 32, 1274, 2655, 7, 80, 749, 1254]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized sample question: {}'.format(tokenizer.encode(train_data['document'][20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a32b1fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [570, 892, 36, 584, 159, 7091, 201]\n",
      "기존 문장: 보면서 웃지 않는 건 불가능하다\n"
     ]
    }
   ],
   "source": [
    "sample_string = train_data['document'][21]\n",
    "\n",
    "# 인코딩한 결과를 tokenized_string에 저장\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# 이를 다시 디코딩\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41d7c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [4, 23, 1364, 2157, 8235, 8128, 8130, 8235, 8147, 8169, 8235, 8147, 8169, 393]\n",
      "기존 문장: 이 영화 굉장히 재밌다 킄핫핫ㅎ\n"
     ]
    }
   ],
   "source": [
    "sample_string = '이 영화 굉장히 재밌다 킄핫핫ㅎ'\n",
    "\n",
    "# 인코딩한 결과를 tokenized_string에 저장\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# 이를 다시 디코딩\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5960e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ----> 이 \n",
      "23 ----> 영화 \n",
      "1364 ----> 굉장히 \n",
      "2157 ----> 재밌다 \n",
      "8235 ----> �\n",
      "8128 ----> �\n",
      "8130 ----> �\n",
      "8235 ----> �\n",
      "8147 ----> �\n",
      "8169 ----> �\n",
      "8235 ----> �\n",
      "8147 ----> �\n",
      "8169 ----> �\n",
      "393 ----> ㅎ\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9203529",
   "metadata": {},
   "source": [
    "## 마르코프 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c191927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "import urllib.request\n",
    "import os, re, json, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb102be",
   "metadata": {},
   "source": [
    "### 데이터 등록하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ac950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리에 데이터 등록하기\n",
    "def set_word3(dic, s3):\n",
    "    w1, w2, w3 = s3\n",
    "    if not w1 in dic: dic[w1] = {}\n",
    "    if not w2 in dic[w1]: dic[w1][w2] = {}\n",
    "    if not w3 in dic[w1][w2]: dic[w1][w2][w3] = 0\n",
    "    dic[w1][w2][w3] += 1\n",
    "    \n",
    "    # 마르코프 체인 딕셔너리 만들기\n",
    "def make_dic(words):\n",
    "    tmp = [\"@\"]\n",
    "    dic = {}\n",
    "    for word in words:\n",
    "        tmp.append(word)\n",
    "        if len(tmp) < 3: continue\n",
    "        if len(tmp) > 3: tmp = tmp[1:]\n",
    "        set_word3(dic, tmp)\n",
    "        if word == \".\":\n",
    "            tmp = [\"@\"]\n",
    "            continue\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d8fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'이며': {'이윽고': 1}, '마라': {'\\n': 3, '.': 3}, '은': {'마라': 2, '안': 1}, '할': {'것': 1}, '말고': {'마저': 1, '처': 1}, '들': {'을': 1}, '을': {'다': 1}, '이': {'있고': 1, '있더라고': 1, '없을': 1, '요': 1}, '말': {'게': 1}, '일세': {'.': 1}, '하실': {'것': 1}, '이고': {'송장': 1, '\\n': 1}, '이제': {'.': 1}, '이다': {'그': 1}}\n"
     ]
    }
   ],
   "source": [
    "# 문장 읽어 들이기\n",
    "dict_file = \"./data/markov-toji.json\"\n",
    "\n",
    "if not os.path.exists(dict_file):\n",
    "    # 토지 텍스트 파일 읽어 들이기\n",
    "    fp = codecs.open(\"./data/BEXX0003.txt\", \"r\", encoding=\"utf-16\")\n",
    "    soup = BeautifulSoup(fp, \"html.parser\")\n",
    "    body = soup.select_one(\"body > text\")\n",
    "    text = body.getText()\n",
    "    text = text.replace(\"…\", \"\") # 현재 koNLPy가 …을 구두점으로 잡지 못하는 문제 임시 해결\n",
    "    # 형태소 분석\n",
    "    twitter = Twitter()\n",
    "    malist = twitter.pos(text, norm=True)\n",
    "    words = []\n",
    "    for word in malist:\n",
    "        # 구두점 등은 대상에서 제외(단 마침표는 포함)\n",
    "        if not word[1] in [\"Punctuation\"]:\n",
    "            words.append(word[0])\n",
    "        if word[0] == \".\":\n",
    "            words.append(word[0])\n",
    "    # 딕셔너리 생성\n",
    "    dic = make_dic(words)\n",
    "    json.dump(dic, open(dict_file,\"w\", encoding=\"utf-8\"))\n",
    "else:\n",
    "    dic = json.load(open(dict_file,\"r\"))\n",
    "    \n",
    "print(dic['걱정'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d10649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a943ef52",
   "metadata": {},
   "source": [
    "## 글자 레벨 기계 번역기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3ca7b",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e4edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c51676",
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8ae419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190206"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af686dd1",
   "metadata": {},
   "source": [
    "### 6만개 의 데이터 만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb1b31c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17676</th>\n",
       "      <td>He's a gentleman.</td>\n",
       "      <td>C'est un gentleman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40251</th>\n",
       "      <td>He didn't get caught.</td>\n",
       "      <td>Il ne se fit pas prendre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>I hiccup a lot.</td>\n",
       "      <td>J'ai souvent le hoquet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38083</th>\n",
       "      <td>Utilities are extra.</td>\n",
       "      <td>Les frais annexes ne sont pas compris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20052</th>\n",
       "      <td>They despise you.</td>\n",
       "      <td>Elles te méprisent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24324</th>\n",
       "      <td>It was horrendous.</td>\n",
       "      <td>Ça a été épouvantable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55669</th>\n",
       "      <td>I wouldn't bet on that.</td>\n",
       "      <td>Je ne parierais pas là-dessus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>Is that right?</td>\n",
       "      <td>En est-il ainsi ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59948</th>\n",
       "      <td>All of us stared at her.</td>\n",
       "      <td>Nous la fixions toutes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51878</th>\n",
       "      <td>What are you drinking?</td>\n",
       "      <td>Qu'es-tu en train de boire ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            src                                     tar\n",
       "17676         He's a gentleman.                     C'est un gentleman.\n",
       "40251     He didn't get caught.               Il ne se fit pas prendre.\n",
       "10216           I hiccup a lot.                 J'ai souvent le hoquet.\n",
       "38083      Utilities are extra.  Les frais annexes ne sont pas compris.\n",
       "20052         They despise you.                     Elles te méprisent.\n",
       "24324        It was horrendous.                  Ça a été épouvantable.\n",
       "55669   I wouldn't bet on that.          Je ne parierais pas là-dessus.\n",
       "7706             Is that right?                       En est-il ainsi ?\n",
       "59948  All of us stared at her.                 Nous la fixions toutes.\n",
       "51878    What are you drinking?            Qu'es-tu en train de boire ?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96e1c1",
   "metadata": {},
   "source": [
    "### 시작 과 종료 태그 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04845841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43984</th>\n",
       "      <td>They walked upstairs.</td>\n",
       "      <td>\\t Ils montèrent des escaliers. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45488</th>\n",
       "      <td>Why do stars twinkle?</td>\n",
       "      <td>\\t Pourquoi les étoiles brillent-elles ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>Go find out.</td>\n",
       "      <td>\\t Allez voir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22760</th>\n",
       "      <td>He's already left.</td>\n",
       "      <td>\\t Il est déjà parti. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42967</th>\n",
       "      <td>Maybe we should pray.</td>\n",
       "      <td>\\t Peut-être devrions-nous prier. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29972</th>\n",
       "      <td>It is too long ago.</td>\n",
       "      <td>\\t C'est il y a trop longtemps. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>We're clean.</td>\n",
       "      <td>\\t Nous sommes propres. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34074</th>\n",
       "      <td>He had fun with her.</td>\n",
       "      <td>\\t Il s'est amusé avec elle. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>Tom says hi.</td>\n",
       "      <td>\\t Tom vous salue bien. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44426</th>\n",
       "      <td>Tom is really clever.</td>\n",
       "      <td>\\t Tom est très intelligent. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                                          tar\n",
       "43984  They walked upstairs.           \\t Ils montèrent des escaliers. \\n\n",
       "45488  Why do stars twinkle?  \\t Pourquoi les étoiles brillent-elles ? \\n\n",
       "2851            Go find out.                            \\t Allez voir. \\n\n",
       "22760     He's already left.                     \\t Il est déjà parti. \\n\n",
       "42967  Maybe we should pray.         \\t Peut-être devrions-nous prier. \\n\n",
       "29972    It is too long ago.           \\t C'est il y a trop longtemps. \\n\n",
       "4069            We're clean.                   \\t Nous sommes propres. \\n\n",
       "34074   He had fun with her.              \\t Il s'est amusé avec elle. \\n\n",
       "3908            Tom says hi.                   \\t Tom vous salue bien. \\n\n",
       "44426  Tom is really clever.              \\t Tom est très intelligent. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836438dd",
   "metadata": {},
   "source": [
    "### 글자 집합 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4ea5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "src_vocab=set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)\n",
    "        \n",
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f5e6b",
   "metadata": {},
   "source": [
    "### 정렬하여 순서를 정해준 뒤에 인덱스를 사용하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe56b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832aef01",
   "metadata": {},
   "source": [
    "### 각 글자에 인덱스를 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c4a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b7fdc",
   "metadata": {},
   "source": [
    "### 인덱스가 부여된 글자 집합으로부터 갖고있는 훈련 데이터에 정수 인코딩을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff2fc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b1c95",
   "metadata": {},
   "source": [
    "### 프랑스어에 대한 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c25cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119fdd7",
   "metadata": {},
   "source": [
    "### 실제값 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2550f464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 48, 53, 3, 4, 3, 2], [3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868bbfa",
   "metadata": {},
   "source": [
    "### 패딩 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "451c1666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08489a66",
   "metadata": {},
   "source": [
    "### 원 핫 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d12fb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af312b",
   "metadata": {},
   "source": [
    "### 층 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91c3a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5157ab",
   "metadata": {},
   "source": [
    "### 인코더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57431b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 16:20:41.364032: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec87770",
   "metadata": {},
   "source": [
    "### 디코더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d08632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cef4e",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14f02b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 16:26:27.675747: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 153s 201ms/step - loss: 0.7425 - val_loss: 0.6685\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.4669 - val_loss: 0.5469\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.3878 - val_loss: 0.4747\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 136s 182ms/step - loss: 0.3446 - val_loss: 0.4382\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 136s 181ms/step - loss: 0.3156 - val_loss: 0.4131\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 133s 177ms/step - loss: 0.2941 - val_loss: 0.3934\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 133s 178ms/step - loss: 0.2773 - val_loss: 0.3823\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 134s 179ms/step - loss: 0.2639 - val_loss: 0.3714\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 134s 178ms/step - loss: 0.2527 - val_loss: 0.3655\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 999s 1s/step - loss: 0.2429 - val_loss: 0.3598\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 144s 191ms/step - loss: 0.2347 - val_loss: 0.3564\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.2271 - val_loss: 0.3534\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.2203 - val_loss: 0.3514\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 150s 199ms/step - loss: 0.2142 - val_loss: 0.3495\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 155s 207ms/step - loss: 0.2085 - val_loss: 0.3496\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 150s 199ms/step - loss: 0.2034 - val_loss: 0.3492\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.1984 - val_loss: 0.3477\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 146s 195ms/step - loss: 0.1939 - val_loss: 0.3485\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 145s 194ms/step - loss: 0.1896 - val_loss: 0.3494\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 144s 191ms/step - loss: 0.1856 - val_loss: 0.3509\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 146s 194ms/step - loss: 0.1818 - val_loss: 0.3536\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 144s 193ms/step - loss: 0.1783 - val_loss: 0.3537\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.1749 - val_loss: 0.3569\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 145s 194ms/step - loss: 0.1717 - val_loss: 0.3601\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 167s 223ms/step - loss: 0.1686 - val_loss: 0.3594\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 150s 201ms/step - loss: 0.1657 - val_loss: 0.3618\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.1629 - val_loss: 0.3635\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 149s 199ms/step - loss: 0.1603 - val_loss: 0.3654\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.1576 - val_loss: 0.3686\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 135s 180ms/step - loss: 0.1552 - val_loss: 0.3711\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 409s 545ms/step - loss: 0.1529 - val_loss: 0.3721\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 375s 500ms/step - loss: 0.1506 - val_loss: 0.3765\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 140s 186ms/step - loss: 0.1484 - val_loss: 0.3784\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 137s 183ms/step - loss: 0.1465 - val_loss: 0.3808\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.1444 - val_loss: 0.3844\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.1425 - val_loss: 0.3880\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.1407 - val_loss: 0.3899\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.1389 - val_loss: 0.3933\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.1373 - val_loss: 0.3949\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 2765s 4s/step - loss: 0.1355 - val_loss: 0.3996\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 150s 200ms/step - loss: 0.1341 - val_loss: 0.4001\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 150s 199ms/step - loss: 0.1326 - val_loss: 0.4014\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 151s 202ms/step - loss: 0.1309 - val_loss: 0.4059\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 136s 182ms/step - loss: 0.1297 - val_loss: 0.4077\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 136s 181ms/step - loss: 0.1284 - val_loss: 0.4110\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 136s 182ms/step - loss: 0.1269 - val_loss: 0.4133\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 136s 181ms/step - loss: 0.1255 - val_loss: 0.4158\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 3023s 4s/step - loss: 0.1243 - val_loss: 0.4200\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 25026s 33s/step - loss: 0.1231 - val_loss: 0.4201\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 12840s 17s/step - loss: 0.1219 - val_loss: 0.4254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f930f4709a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f72fa",
   "metadata": {},
   "source": [
    "### 기계 번역기 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04b954cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더를 정의 encoder_inputs와 encoder_states는 훈련 과정에서 이미 정의한 것들을 재사용 \n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cf54cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디코더를 설계\n",
    "#이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b37a540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인덱스로부터 단어를 얻을 수 있는 index_to_src와 index_to_tar를 생성\n",
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22287e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eb2b23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Hi.\n",
      "정답 문장:  Salut ! \n",
      "번역기가 번역한 문장:  Salut. \n",
      "-----------------------------------\n",
      "입력 문장: I see.\n",
      "정답 문장:  Aha. \n",
      "번역기가 번역한 문장:  Je ne seurs pas demain. \n",
      "-----------------------------------\n",
      "입력 문장: Hug me.\n",
      "정답 문장:  Serrez-moi dans vos bras ! \n",
      "번역기가 번역한 문장:  Serre-moi dans tes bras ! \n",
      "-----------------------------------\n",
      "입력 문장: Hold it!\n",
      "정답 문장:  Restez où vous êtes ! \n",
      "번역기가 번역한 문장:  Ne bouge plus. \n",
      "-----------------------------------\n",
      "입력 문장: I crashed.\n",
      "정답 문장:  Je me suis écrasée. \n",
      "번역기가 번역한 문장:  Je me suis entraîné. \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cba1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fc7fde4",
   "metadata": {},
   "source": [
    "## 단어 레벨 번역기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3ff923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75beae8d",
   "metadata": {},
   "source": [
    "### 데이터 가져오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f79db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4d58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2dd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c42282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ed13b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "b'avez vous deja dine ?'\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10fd47",
   "metadata": {},
   "source": [
    "### 모든 전처리를 수행해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf88e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfcbaa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n",
      "[['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "#데이터 확인\n",
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff149dc",
   "metadata": {},
   "source": [
    "### 케라스를 이용한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816e880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input: (33000, 8)\n",
      "decoder_input: (33000, 16)\n",
      "decoder_target: (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")\n",
    "\n",
    "print(\"encoder_input:\", encoder_input.shape)\n",
    "print(\"decoder_input:\", decoder_input.shape)\n",
    "print(\"decoder_target:\", decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9ceec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4606, 프랑스어 단어 집합의 크기 : 8107\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ee8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45c52b",
   "metadata": {},
   "source": [
    "### 테스트 데이터를 분리\n",
    "### 테스트 데이터를 분리하기 전에 적절한 분포를 갖도록 데이터를 섞어주는 과정을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "506c3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31098 16068 31980 ...  6427 24752 32081]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8057b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02efff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22,  47, 266,   1,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a0d0dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  42,  72,  67,  37, 395,   1,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6934f5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42,  72,  67,  37, 395,   1,   3,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target[30997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abdf0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(33000*0.1)\n",
    "print(n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9661a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29700, 8)\n",
      "(29700, 16)\n",
      "(29700, 16)\n",
      "(3300, 8)\n",
      "(3300, 16)\n",
      "(3300, 16)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9464572",
   "metadata": {},
   "source": [
    "### 기계 번역기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d12a9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#임베딩 벡터와 LSTM의 은닉 상태의 크기를 특정 크기로 고정\n",
    "#여기서는 50을 사용\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1613a0",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "313bd6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 07:19:21.609980: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047a70a",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7db2becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be50c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     230300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     405350      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8107)   413457      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,089,507\n",
      "Trainable params: 1,089,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "120dcf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 07:22:50.653272: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 49s 188ms/step - loss: 3.1224 - acc: 0.6191 - val_loss: 1.8447 - val_acc: 0.6505\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 44s 187ms/step - loss: 1.6706 - acc: 0.7358 - val_loss: 1.5565 - val_acc: 0.7542\n",
      "Epoch 3/50\n",
      "233/233 [==============================] - 42s 179ms/step - loss: 1.4828 - acc: 0.7595 - val_loss: 1.4489 - val_acc: 0.7663\n",
      "Epoch 4/50\n",
      "233/233 [==============================] - 41s 177ms/step - loss: 1.3869 - acc: 0.7727 - val_loss: 1.3849 - val_acc: 0.7806\n",
      "Epoch 5/50\n",
      "233/233 [==============================] - 41s 175ms/step - loss: 1.3118 - acc: 0.7856 - val_loss: 1.3085 - val_acc: 0.7918\n",
      "Epoch 6/50\n",
      "233/233 [==============================] - 42s 179ms/step - loss: 1.2527 - acc: 0.7949 - val_loss: 1.2661 - val_acc: 0.7988\n",
      "Epoch 7/50\n",
      "233/233 [==============================] - 42s 180ms/step - loss: 1.2027 - acc: 0.8025 - val_loss: 1.2220 - val_acc: 0.8051\n",
      "Epoch 8/50\n",
      "233/233 [==============================] - 40s 173ms/step - loss: 1.1597 - acc: 0.8096 - val_loss: 1.1892 - val_acc: 0.8115\n",
      "Epoch 9/50\n",
      "233/233 [==============================] - 39s 170ms/step - loss: 1.1216 - acc: 0.8158 - val_loss: 1.1830 - val_acc: 0.8118\n",
      "Epoch 10/50\n",
      "233/233 [==============================] - 40s 173ms/step - loss: 1.0878 - acc: 0.8210 - val_loss: 1.1300 - val_acc: 0.8217\n",
      "Epoch 11/50\n",
      "233/233 [==============================] - 39s 168ms/step - loss: 1.0568 - acc: 0.8252 - val_loss: 1.1173 - val_acc: 0.8217\n",
      "Epoch 12/50\n",
      "233/233 [==============================] - 39s 168ms/step - loss: 1.0287 - acc: 0.8289 - val_loss: 1.1007 - val_acc: 0.8239\n",
      "Epoch 13/50\n",
      "233/233 [==============================] - 40s 171ms/step - loss: 1.0036 - acc: 0.8325 - val_loss: 1.0803 - val_acc: 0.8285\n",
      "Epoch 14/50\n",
      "233/233 [==============================] - 40s 173ms/step - loss: 0.9806 - acc: 0.8357 - val_loss: 1.0572 - val_acc: 0.8299\n",
      "Epoch 15/50\n",
      "233/233 [==============================] - 40s 171ms/step - loss: 0.9596 - acc: 0.8382 - val_loss: 1.0415 - val_acc: 0.8324\n",
      "Epoch 16/50\n",
      "233/233 [==============================] - 41s 176ms/step - loss: 0.9404 - acc: 0.8410 - val_loss: 1.0195 - val_acc: 0.8366\n",
      "Epoch 17/50\n",
      "233/233 [==============================] - 40s 174ms/step - loss: 0.9231 - acc: 0.8434 - val_loss: 1.0080 - val_acc: 0.8376\n",
      "Epoch 18/50\n",
      "233/233 [==============================] - 40s 170ms/step - loss: 0.9071 - acc: 0.8458 - val_loss: 1.0078 - val_acc: 0.8370\n",
      "Epoch 19/50\n",
      "233/233 [==============================] - 39s 168ms/step - loss: 0.8925 - acc: 0.8479 - val_loss: 0.9864 - val_acc: 0.8409\n",
      "Epoch 20/50\n",
      "233/233 [==============================] - 39s 168ms/step - loss: 0.8789 - acc: 0.8500 - val_loss: 0.9856 - val_acc: 0.8408\n",
      "Epoch 21/50\n",
      "233/233 [==============================] - 40s 173ms/step - loss: 0.8655 - acc: 0.8517 - val_loss: 0.9741 - val_acc: 0.8431\n",
      "Epoch 22/50\n",
      "233/233 [==============================] - 40s 171ms/step - loss: 0.8525 - acc: 0.8535 - val_loss: 0.9869 - val_acc: 0.8401\n",
      "Epoch 23/50\n",
      "233/233 [==============================] - 40s 172ms/step - loss: 0.8404 - acc: 0.8554 - val_loss: 0.9588 - val_acc: 0.8445\n",
      "Epoch 24/50\n",
      "233/233 [==============================] - 40s 172ms/step - loss: 0.8286 - acc: 0.8571 - val_loss: 0.9509 - val_acc: 0.8461\n",
      "Epoch 25/50\n",
      "233/233 [==============================] - 39s 166ms/step - loss: 0.8178 - acc: 0.8586 - val_loss: 0.9423 - val_acc: 0.8469\n",
      "Epoch 26/50\n",
      "233/233 [==============================] - 40s 174ms/step - loss: 0.8081 - acc: 0.8602 - val_loss: 0.9367 - val_acc: 0.8479\n",
      "Epoch 27/50\n",
      "233/233 [==============================] - 39s 169ms/step - loss: 0.7987 - acc: 0.8616 - val_loss: 0.9287 - val_acc: 0.8491\n",
      "Epoch 28/50\n",
      "233/233 [==============================] - 39s 168ms/step - loss: 0.7888 - acc: 0.8630 - val_loss: 0.9285 - val_acc: 0.8484\n",
      "Epoch 29/50\n",
      "233/233 [==============================] - 40s 172ms/step - loss: 0.7794 - acc: 0.8643 - val_loss: 0.9226 - val_acc: 0.8500\n",
      "Epoch 30/50\n",
      "233/233 [==============================] - 40s 170ms/step - loss: 0.7704 - acc: 0.8657 - val_loss: 0.9179 - val_acc: 0.8507\n",
      "Epoch 31/50\n",
      "233/233 [==============================] - 41s 176ms/step - loss: 0.7619 - acc: 0.8673 - val_loss: 0.9102 - val_acc: 0.8516\n",
      "Epoch 32/50\n",
      "233/233 [==============================] - 41s 175ms/step - loss: 0.7540 - acc: 0.8683 - val_loss: 0.9103 - val_acc: 0.8519\n",
      "Epoch 33/50\n",
      "233/233 [==============================] - 42s 179ms/step - loss: 0.7467 - acc: 0.8697 - val_loss: 0.9079 - val_acc: 0.8515\n",
      "Epoch 34/50\n",
      "233/233 [==============================] - 41s 178ms/step - loss: 0.7397 - acc: 0.8710 - val_loss: 0.9195 - val_acc: 0.8498\n",
      "Epoch 35/50\n",
      "233/233 [==============================] - 41s 174ms/step - loss: 0.7334 - acc: 0.8720 - val_loss: 0.8929 - val_acc: 0.8547\n",
      "Epoch 36/50\n",
      "233/233 [==============================] - 39s 169ms/step - loss: 0.7273 - acc: 0.8732 - val_loss: 0.8972 - val_acc: 0.8544\n",
      "Epoch 37/50\n",
      "233/233 [==============================] - 40s 173ms/step - loss: 0.7210 - acc: 0.8745 - val_loss: 0.9184 - val_acc: 0.8516\n",
      "Epoch 38/50\n",
      "233/233 [==============================] - 41s 174ms/step - loss: 0.7150 - acc: 0.8754 - val_loss: 0.8875 - val_acc: 0.8550\n",
      "Epoch 39/50\n",
      "233/233 [==============================] - 41s 176ms/step - loss: 0.7084 - acc: 0.8767 - val_loss: 0.9029 - val_acc: 0.8525\n",
      "Epoch 40/50\n",
      "233/233 [==============================] - 40s 171ms/step - loss: 0.7023 - acc: 0.8780 - val_loss: 0.8789 - val_acc: 0.8576\n",
      "Epoch 41/50\n",
      "233/233 [==============================] - 39s 166ms/step - loss: 0.6960 - acc: 0.8789 - val_loss: 0.8874 - val_acc: 0.8548\n",
      "Epoch 42/50\n",
      "233/233 [==============================] - 39s 167ms/step - loss: 0.6902 - acc: 0.8801 - val_loss: 0.8728 - val_acc: 0.8575\n",
      "Epoch 43/50\n",
      "233/233 [==============================] - 39s 167ms/step - loss: 0.6847 - acc: 0.8812 - val_loss: 0.8786 - val_acc: 0.8568\n",
      "Epoch 44/50\n",
      "233/233 [==============================] - 39s 167ms/step - loss: 0.6797 - acc: 0.8818 - val_loss: 0.8780 - val_acc: 0.8580\n",
      "Epoch 45/50\n",
      "233/233 [==============================] - 39s 167ms/step - loss: 0.6746 - acc: 0.8832 - val_loss: 0.8743 - val_acc: 0.8580\n",
      "Epoch 46/50\n",
      "233/233 [==============================] - 39s 166ms/step - loss: 0.6697 - acc: 0.8840 - val_loss: 0.8672 - val_acc: 0.8595\n",
      "Epoch 47/50\n",
      "233/233 [==============================] - 39s 166ms/step - loss: 0.6652 - acc: 0.8850 - val_loss: 0.8750 - val_acc: 0.8588\n",
      "Epoch 48/50\n",
      "233/233 [==============================] - 39s 167ms/step - loss: 0.6606 - acc: 0.8858 - val_loss: 0.8740 - val_acc: 0.8593\n",
      "Epoch 49/50\n",
      "233/233 [==============================] - 39s 167ms/step - loss: 0.6563 - acc: 0.8869 - val_loss: 0.8692 - val_acc: 0.8593\n",
      "Epoch 50/50\n",
      "233/233 [==============================] - 39s 168ms/step - loss: 0.6518 - acc: 0.8874 - val_loss: 0.8647 - val_acc: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb4be40b400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897901f3",
   "metadata": {},
   "source": [
    "### 번역기 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a65c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65694eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df853b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c18fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 과정에서의 동작을 위한 decode_sequence 함수를 구현\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44d523e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인을 위한 함수\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_src[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4643264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  i wasn t drunk . \n",
      "번역문 : je n etais pas saoul . \n",
      "예측문 :  je n etais pas aide . \n",
      "\n",
      "\n",
      "원문 :  termites eat wood . \n",
      "번역문 : les termites mangent du bois . \n",
      "예측문 :  les chambre . \n",
      "\n",
      "\n",
      "원문 :  go away . \n",
      "번역문 : pars d ici . \n",
      "예측문 :  va t en ! \n",
      "\n",
      "\n",
      "원문 :  speed up . \n",
      "번역문 : accelerez . \n",
      "예측문 :  donne un peu . \n",
      "\n",
      "\n",
      "원문 :  no one saw that . \n",
      "번역문 : personne ne l a vu . \n",
      "예측문 :  personne n a vu ca . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력\n",
    "for seq_index in [3,50,100,300,1001]:\n",
    "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[:-5])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b86369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  i hate this car . \n",
      "번역문 : je deteste cette voiture . \n",
      "예측문 :  je m aime . \n",
      "\n",
      "\n",
      "원문 :  i like a challenge . \n",
      "번역문 : j aime le defi . \n",
      "예측문 :  j aime le moi . \n",
      "\n",
      "\n",
      "원문 :  who is next ? \n",
      "번역문 : a qui le tour ? \n",
      "예측문 :  qui est il la tete ? \n",
      "\n",
      "\n",
      "원문 :  you are stupid . \n",
      "번역문 : tu es stupide . \n",
      "예측문 :  vous etes bonne . \n",
      "\n",
      "\n",
      "원문 :  that s a myth . \n",
      "번역문 : il s agit d un mythe . \n",
      "예측문 :  c est un probleme . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력\n",
    "for seq_index in [3,50,100,300,1001]:\n",
    "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "  print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[:-5])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facbd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b350743",
   "metadata": {},
   "source": [
    "## BLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e871a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18464a",
   "metadata": {},
   "source": [
    "### 보정된 유니그램 정밀도 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3ec93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 카운트 함수\n",
    "def simple_count(tokens, n): # 토큰화 된 candidate 문장, n-gram에서의 n 이 두 가지를 인자로 받음.\n",
    "    return Counter(ngrams(tokens, n)) #문장에서 n-gram을 카운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fcc8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the',): 3, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('which',): 1, ('ensures',): 1, ('that',): 1, ('military',): 1, ('always',): 1, ('obeys',): 1, ('commands',): 1, ('of',): 1, ('party.',): 1})\n"
     ]
    }
   ],
   "source": [
    "candidate = \"It is a guide to action which ensures that the military always obeys the commands of the party.\"\n",
    "tokens = candidate.split() #단어 토큰화\n",
    "result = simple_count(tokens, 1) #토큰화 된 문장, 유니그램의 개수를 구하고자 한다면 n=1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4256cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the',): 7})\n"
     ]
    }
   ],
   "source": [
    "candidate = 'the the the the the the the'\n",
    "tokens = candidate.split() #단어 토큰화\n",
    "result = simple_count(tokens, 1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59dc9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clip(candidate, reference_list, n):\n",
    "    cnt_ca = simple_count(candidate, n)\n",
    "    # Ca 문장에서 n-gram 카운트\n",
    "    temp = dict()\n",
    "\n",
    "    for ref in reference_list: # 다수의 Ref 문장에 대해서 이하 반복\n",
    "        cnt_ref = simple_count(ref, n)\n",
    "        # Ref 문장에서 n-gram 카운트\n",
    "\n",
    "        for n_gram in cnt_ref: # 모든 Ref에 대해서 비교하여 특정 n-gram이 하나의 Ref에 가장 많이 등장한 횟수를 저장\n",
    "            if n_gram in temp:\n",
    "                temp[n_gram] = max(cnt_ref[n_gram], temp[n_gram]) # max_ref_count\n",
    "            else:\n",
    "                temp[n_gram] = cnt_ref[n_gram]\n",
    "\n",
    "    return {\n",
    "        n_gram: min(cnt_ca.get(n_gram, 0), temp.get(n_gram, 0)) for n_gram in cnt_ca\n",
    "        # count_clip=min(count, max_ref_count)\n",
    "        # 위의 get은 찾고자 하는 n-gram이 없으면 0을 반환한다.\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5edeb3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('the',): 2}\n"
     ]
    }
   ],
   "source": [
    "candidate = 'the the the the the the the'\n",
    "references = [\n",
    "    'the cat is on the mat',\n",
    "    'there is a cat on the mat'\n",
    "]\n",
    "result = count_clip(candidate.split(),list(map(lambda ref: ref.split(), references)),1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f52bb",
   "metadata": {},
   "source": [
    "### 보정된 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8535805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_precision(candidate, reference_list, n):\n",
    "    clip = count_clip(candidate, reference_list, n) \n",
    "    total_clip = sum(clip.values()) # 분자\n",
    "\n",
    "    ct = simple_count(candidate, n)\n",
    "    total_ct = sum(ct.values()) #분모\n",
    "\n",
    "    if total_ct==0: # n-gram의 n이 커졌을 때 분모가 0이 되는 것을 방지\n",
    "      total_ct=1\n",
    "\n",
    "    return (total_clip / total_ct) # 보정된 정밀도\n",
    "    # count_clip의 합을 분자로 하고 단순 count의 합을 분모로 하면 보정된 정밀도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a9a32fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "result=modified_precision(candidate.split(),list(map(lambda ref: ref.split(), references)),1) # 유니그램이므로 n=1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88244d0",
   "metadata": {},
   "source": [
    "### r을 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0736b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_ref_length(candidate, reference_list): # Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n",
    "    ca_len = len(candidate) # ca 길이\n",
    "    ref_lens = (len(ref) for ref in reference_list) # Ref들의 길이\n",
    "    closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n",
    "    # 길이 차이를 최소화하는 Ref를 찾아서 Ref의 길이를 리턴\n",
    "    return closest_ref_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8260ee",
   "metadata": {},
   "source": [
    "### BP를 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64ac7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference_list):\n",
    "    ca_len = len(candidate)\n",
    "    ref_len = closest_ref_length(candidate, reference_list)\n",
    "\n",
    "    if ca_len > ref_len:\n",
    "        return 1\n",
    "    elif ca_len == 0 :\n",
    "    # candidate가 비어있다면 BP = 0 → BLEU = 0.0\n",
    "        return 0\n",
    "    else:\n",
    "        return np.exp(1 - ref_len/ca_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf82a1",
   "metadata": {},
   "source": [
    "### BLUE를 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2465e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    bp = brevity_penalty(candidate, reference_list) # 브레버티 패널티, BP\n",
    "\n",
    "    p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights,start=1)] \n",
    "    #p1, p2, p3, ..., pn\n",
    "    score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
    "    return bp * np.exp(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303759fd",
   "metadata": {},
   "source": [
    "### NLTK를 이용한 BLUE 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a72a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5045666840058485\n",
      "0.5045666840058485\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "\n",
    "candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "references = [\n",
    "    'It is a guide to action that ensures that the military will forever heed Party commands',\n",
    "    'It is the guiding principle which guarantees the military forces always being under the command of the Party',\n",
    "    'It is the practical guide for the army always to heed the directions of the party'\n",
    "]\n",
    "\n",
    "print(bleu_score(candidate.split(),list(map(lambda ref: ref.split(), references))))\n",
    "# 이번 챕터에서 구현한 코드로 계산한 BLEU 점수\n",
    "print(bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))\n",
    "# NLTK 패키지 구현되어져 있는 코드로 계산한 BLEU 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be93ab7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e7fab0",
   "metadata": {},
   "source": [
    "## 네이버 영화 리뷰를 와 LSTM을 이용한 자연어 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75b13dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa73a8",
   "metadata": {},
   "source": [
    "### 네이버 영화리뷰 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24ae022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tf.keras.utils.get_file(\n",
    "    'ratings_train.txt', \n",
    "    origin='http://cyberadam.cafe24.com/movieimage/ratings_train.txt', \n",
    "    extract=True)\n",
    "\n",
    "df = pd.read_csv(file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4d9811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>9856453</td>\n",
       "      <td>정말 최고의 명작 성인이 되고 본 이집트의 왕자는 또 다른 감동 그자체네요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6961803</td>\n",
       "      <td>이영화만 성공 했어도 스퀘어가 에닉스랑 합병 할일은 없었을텐데..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>8681713</td>\n",
       "      <td>울컥하는 사회현실 ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>5348290</td>\n",
       "      <td>기대를하나도안하면 할일없을때보기좋은영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>9340549</td>\n",
       "      <td>소림사 관문 통과하기 진짜 어렵다는거 보여준 영화..극장에서 개봉하는거 반갑다..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>7357684</td>\n",
       "      <td>시리즈안나오나 ㅠㅠㅠㅠㅠㅠㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>9303587</td>\n",
       "      <td>끝난다는 사실이 너무 슬퍼요. 가슴이 뻥 뚫려버린것같아..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                       document  label\n",
       "1000  9856453      정말 최고의 명작 성인이 되고 본 이집트의 왕자는 또 다른 감동 그자체네요      1\n",
       "1001  6961803           이영화만 성공 했어도 스퀘어가 에닉스랑 합병 할일은 없었을텐데..      0\n",
       "1002  8681713                                   울컥하는 사회현실 ㅠㅠ      1\n",
       "1003  5348290                          기대를하나도안하면 할일없을때보기좋은영화      0\n",
       "1004  9340549  소림사 관문 통과하기 진짜 어렵다는거 보여준 영화..극장에서 개봉하는거 반갑다..      1\n",
       "1005  7357684                               시리즈안나오나 ㅠㅠㅠㅠㅠㅠㅠㅠ      1\n",
       "1006  9303587               끝난다는 사실이 너무 슬퍼요. 가슴이 뻥 뚫려버린것같아..      1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 임의샘플 확인\n",
    "df[1000:1007]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8580ccd",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3707dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 \n",
    "#!pip install konlpy\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# 데이터 전처리\n",
    "def word_tokenization(text):\n",
    "  return [word for word in okt.morphs(text)]\n",
    "\n",
    "def preprocessing(df):\n",
    "  df = df.dropna()\n",
    "  df = df[1000:2000]  # 샘플 데이터 1000개, 학습시간을 줄이고자 함 \n",
    "  df['document'] = df['document'].str.replace(\"[^A-Za-z0-9가-힣ㄱ-ㅎㅏ-ㅣ ]\",\"\")\n",
    "  data =  df['document'].apply((lambda x: word_tokenization(x)))\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b222af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/fxl3_n31121f16yj69fbrb_m0000gn/T/ipykernel_1277/2964453390.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['document'] = df['document'].str.replace(\"[^A-Za-z0-9가-힣ㄱ-ㅎㅏ-ㅣ ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 데이터 1000개 전처리 후 불러오기\n",
    "review = preprocessing(df)\n",
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55e835db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000    [정말, 최고, 의, 명작, 성인, 이, 되고, 본, 이집트, 의, 왕자, 는, 또...\n",
      "1001    [이영화, 만, 성공, 했어도, 스퀘어, 가, 에, 닉스, 랑, 합병, 할, 일, ...\n",
      "1002                                 [울컥, 하는, 사회, 현실, ㅠㅠ]\n",
      "1003       [기대, 를, 하나, 도안, 하, 면, 할, 일, 없을, 때, 보기, 좋은, 영화]\n",
      "1004    [소림사, 관문, 통과, 하기, 진짜, 어렵다는거, 보여준, 영화, 극장, 에서, ...\n",
      "1005                              [시리즈, 안, 나오나, ㅠㅠㅠㅠㅠㅠㅠㅠ]\n",
      "1006        [끝난다는, 사실, 이, 너무, 슬퍼요, 가슴, 이, 뻥, 뚫려, 버린것, 같아]\n",
      "1007                                             [펑점, 조절]\n",
      "1008                            [와이, 건, 진짜, 으리, 으리, 한, 데]\n",
      "1009                                [손발, 이, 오, 그라드, 네, 요]\n",
      "Name: document, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분리된 데이터 확인\n",
    "print(review[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd6cf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[792, 25],\n",
       " [792, 25, 539],\n",
       " [792, 25, 539, 140],\n",
       " [792, 25, 539, 140, 109],\n",
       " [338, 9],\n",
       " [338, 9, 110],\n",
       " [338, 9, 110, 540],\n",
       " [338, 9, 110, 540, 90],\n",
       " [338, 9, 110, 540, 90, 148]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화 및 패딩\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_tokens(review):\n",
    "  tokenizer.fit_on_texts(review)\n",
    "  total_words = len(tokenizer.word_index)+1\n",
    "  tokenized_sentences = tokenizer.texts_to_sequences(review)\n",
    "\n",
    "  input_sequences = []\n",
    "  for token in tokenized_sentences:\n",
    "    for t in range(1, len(token)):\n",
    "        n_gram_sequence = token[:t+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "  return input_sequences, total_words\n",
    "\n",
    "input_sequences, total_words = get_tokens(review)\n",
    "input_sequences[31:40] # n_gram으로 리스트된 데이터샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2aedc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감동 ==>>  46\n",
      "영화 ==>>  2\n",
      "코믹 ==>>  415\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전\n",
    "print(\"감동 ==>> \",tokenizer.word_index['감동'])\n",
    "print(\"영화 ==>> \",tokenizer.word_index['영화'])\n",
    "print(\"코믹 ==>> \",tokenizer.word_index['코믹'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "908e4692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 59\n"
     ]
    }
   ],
   "source": [
    "# 문장의 길이 동일하게 맞추기\n",
    "max_len = max([len(word) for word in input_sequences])\n",
    "print(\"max_len:\", max_len)\n",
    "input_sequences = np.array(pad_sequences(input_sequences, \n",
    "                                         maxlen=max_len, \n",
    "                                         padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "989b2155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력텍스트와 타겟\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X = input_sequences[:,:-1]  # 마지막 값은 제외함\n",
    "y = to_categorical(input_sequences[:,-1], \n",
    "                   num_classes=total_words) # 마지막 값만 이진 클래스 벡터로 변환\n",
    "\n",
    "# y를 설명하기 위한 예시\n",
    "a = to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79bc4020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 72s 181ms/step - loss: 7.7383 - accuracy: 0.0259\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 70s 187ms/step - loss: 7.1627 - accuracy: 0.0321\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 6.7876 - accuracy: 0.0408\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 67s 179ms/step - loss: 6.1776 - accuracy: 0.0613\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 63s 167ms/step - loss: 5.2971 - accuracy: 0.1012\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 62s 166ms/step - loss: 4.3065 - accuracy: 0.1867\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 63s 169ms/step - loss: 3.3556 - accuracy: 0.3430\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 64s 171ms/step - loss: 2.5319 - accuracy: 0.5068\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 66s 175ms/step - loss: 1.8657 - accuracy: 0.6499\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 69s 184ms/step - loss: 1.3786 - accuracy: 0.7520\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 67s 178ms/step - loss: 1.0055 - accuracy: 0.8367\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 66s 176ms/step - loss: 0.7304 - accuracy: 0.8897\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 65s 172ms/step - loss: 0.5367 - accuracy: 0.9246\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 64s 172ms/step - loss: 0.4059 - accuracy: 0.9421\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 64s 172ms/step - loss: 0.3121 - accuracy: 0.9502\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 65s 173ms/step - loss: 0.2566 - accuracy: 0.9557\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 64s 171ms/step - loss: 0.2168 - accuracy: 0.9577\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 64s 172ms/step - loss: 0.1928 - accuracy: 0.9586\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 65s 172ms/step - loss: 0.1785 - accuracy: 0.9587\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 65s 172ms/step - loss: 0.1686 - accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, \n",
    "              output_dim=embedding_dim, \n",
    "              input_length=max_len-1), \n",
    "    Bidirectional(LSTM(units=256)),\n",
    "    Dense(units=total_words, activation='softmax'),\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "048168d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장생성함수 (시작 텍스트, 생성 단어 개수)\n",
    "def text_generation(sos, count):\n",
    "    for _ in range(1, count):\n",
    "        token_list = tokenizer.texts_to_sequences([sos])[0]\n",
    "        token_list = pad_sequences([token_list], \n",
    "                                   maxlen=max_len-1, \n",
    "                                   padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=1) # 최대값 인덱스\n",
    "\n",
    "        for word, idx in tokenizer.word_index.items():\n",
    "            if idx == predicted:\n",
    "                output = word\n",
    "                break\n",
    "        sos += \" \" + output\n",
    "    return sos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8d4af0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmax 설명: 최대값의 인덱스 반환\n",
    "data = [[0.1, 0.2, 0.7], [0.3, 0.5, 0.2], [0.4, 0.3, 0.3]]\n",
    "np.argmax([data], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14504fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'손발 이 오 그라드 네 요 네 요 x 건가 기 한국영 화의'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation(\"연애 하면서\", 12)\n",
    "text_generation(\"꿀잼\", 12)\n",
    "text_generation(\"최고의 영화\", 12)\n",
    "text_generation(\"손발 이\", 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3d209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e4de779",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델로 챗봇 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aba2c1",
   "metadata": {},
   "source": [
    "### Korpora 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05f3eb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Korpora in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from Korpora) (1.19.5)\r\n",
      "Requirement already satisfied: tqdm>=4.46.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from Korpora) (4.59.0)\r\n",
      "Requirement already satisfied: dataclasses>=0.6 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from Korpora) (0.6)\r\n",
      "Requirement already satisfied: xlrd>=1.2.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from Korpora) (2.0.1)\r\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from Korpora) (2.25.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20.0->Korpora) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20.0->Korpora) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20.0->Korpora) (4.0.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20.0->Korpora) (1.26.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Korpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e06af",
   "metadata": {},
   "source": [
    "### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59150329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : songys@github\n",
      "    Repository : https://github.com/songys/Chatbot_data\n",
      "    References :\n",
      "\n",
      "    Chatbot_data_for_Korean v1.0\n",
      "      1. 챗봇 트레이닝용 문답 페어 11,876개\n",
      "      2. 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링\n",
      "    자세한 내용은 위의 repository를 참고하세요.\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `korean_chatbot_data` is already installed at /Users/adam/Korpora/korean_chatbot_data/ChatbotData.csv\n"
     ]
    }
   ],
   "source": [
    "from Korpora import KoreanChatbotKorpus\n",
    "corpus = KoreanChatbotKorpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d395e4",
   "metadata": {},
   "source": [
    "### 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9840e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "('하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.')\n"
     ]
    }
   ],
   "source": [
    "print(corpus.get_all_texts()[:5])\n",
    "print(corpus.get_all_pairs()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee6bba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 12시 땡!\n",
      "A: 하루가 또 가네요.\n"
     ]
    }
   ],
   "source": [
    "# text와 pair가 쌍으로 이루어짐\n",
    "print(\"Q:\", corpus.train[0].text)\n",
    "print(\"A:\", corpus.train[0].pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f347913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "<class 'Korpora.korpora.LabeledSentencePair'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus.get_all_texts()))\n",
    "print(type(corpus.get_all_pairs()))\n",
    "print(type(corpus.train[0]))\n",
    "print(type(corpus.train[0].pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20fe0876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 코퍼스 크기 (11,823개)\n",
    "len(corpus.get_all_texts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8283e1",
   "metadata": {},
   "source": [
    "### 데이터 셋 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "483ec4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2,000개 데이터 셋만 활용 (Google Colab 일 경우 3,000개에서는 메모리 오버되는 현상 발생)\n",
    "texts = []\n",
    "pairs = []\n",
    "for i, (text, pair) in enumerate(zip(corpus.get_all_texts(), corpus.get_all_pairs())):\n",
    "    texts.append(text)\n",
    "    pairs.append(pair)\n",
    "    \n",
    "    #Colab 의 경우 아래 주석 해제 - 메모리가 부족하면 로컬에서도 해제\n",
    "    if i >= 2000: \n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c71febe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('배 아프다', '약이 필요하면 도움을 받아보세요.'),\n",
       " ('배 터지겠네', '위를 좀 쉬게 해주세요.'),\n",
       " ('배 터지겠다.', '산책 좀 해야겠네여.'),\n",
       " ('배가 너무 고파', '뭐 좀 챙겨드세요.'),\n",
       " ('배가 넘넘 고파', '저도 밥 먹고 싶어요')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question와 answer 데이터 확인\n",
    "list(zip(texts, pairs))[1995:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020b12e",
   "metadata": {},
   "source": [
    "### 정규식을 이용한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f21b4f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요\n",
      "텐서플로\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_sentence(sentence):\n",
    "    # 한글, 숫자를 제외한 모든 문자는 제거합니다.\n",
    "    sentence = re.sub(r'[^0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n",
    "    return sentence\n",
    "\n",
    "# 전처리 함수 테스트\n",
    "print(clean_sentence('안녕하세요~:)'))\n",
    "print(clean_sentence('텐서플로^@^%#@!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f46c2",
   "metadata": {},
   "source": [
    "### 한글 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55c4e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: colorama in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from tweepy>=3.7.0->konlpy) (2.25.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# konlpy 설치\n",
    "!pip install konlpy\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "def process_morph(sentence):\n",
    "    return ' '.join(okt.morphs(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ffff3",
   "metadata": {},
   "source": [
    "### 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f811bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_morph(sentence, is_question=True):\n",
    "    # 한글 문장 전처리\n",
    "    sentence = clean_sentence(sentence)\n",
    "    # 형태소 변환\n",
    "    sentence = process_morph(sentence)\n",
    "    # Question 인 경우, Answer인 경우를 분기하여 처리합니다.\n",
    "    if is_question:\n",
    "        return sentence\n",
    "    else:\n",
    "        # START 토큰은 decoder input에 END 토큰은 decoder output에 추가합니다.\n",
    "        return ('<START> ' + sentence, sentence + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4d2ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts, pairs):\n",
    "    questions = []\n",
    "    answer_in = []\n",
    "    answer_out = []\n",
    "\n",
    "    # 질의에 대한 전처리\n",
    "    for text in texts:\n",
    "        # 전처리와 morph 수행\n",
    "        question = clean_and_morph(text, is_question=True)\n",
    "        questions.append(question)\n",
    "\n",
    "    # 답변에 대한 전처리\n",
    "    for pair in pairs:\n",
    "        # 전처리와 morph 수행\n",
    "        in_, out_ = clean_and_morph(pair, is_question=False)\n",
    "        answer_in.append(in_)\n",
    "        answer_out.append(out_)\n",
    "    \n",
    "    return questions, answer_in, answer_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da022a7",
   "metadata": {},
   "source": [
    "### 데이터 생성 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3461c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡', '1 지망 학교 떨어졌어']\n",
      "['<START> 하루 가 또 가네요', '<START> 위로 해 드립니다']\n",
      "['하루 가 또 가네요 <END>', '위로 해 드립니다 <END>']\n"
     ]
    }
   ],
   "source": [
    "questions, answer_in, answer_out = preprocess(texts, pairs)\n",
    "print(questions[:2])\n",
    "print(answer_in[:2])\n",
    "print(answer_out[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542d1f1",
   "metadata": {},
   "source": [
    "### 데이터를 하나의 리스트로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2135829",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = questions + answer_in + answer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7898d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불어오기\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# WARNING 무시\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738212a",
   "metadata": {},
   "source": [
    "### 단어 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7e3c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f1155cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV>\t -> \t1\n",
      "<START>\t -> \t2\n",
      "<END>\t -> \t3\n",
      "이\t -> \t4\n",
      "을\t -> \t5\n",
      "거\t -> \t6\n",
      "가\t -> \t7\n",
      "예요\t -> \t8\n",
      "도\t -> \t9\n",
      "해보세요\t -> \t10\n",
      "요\t -> \t11\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 확인\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    print(f'{word}\\t -> \\t{idx}')\n",
    "    if idx > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15fab29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3604"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f554f",
   "metadata": {},
   "source": [
    "### 텍스트를 시퀀스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3605903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 치환: 텍스트를 시퀀스로 인코딩 (texts_to_sequences)\n",
    "question_sequence = tokenizer.texts_to_sequences(questions)\n",
    "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
    "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)\n",
    "\n",
    "# 문장의 길이 맞추기 (pad_sequences)\n",
    "MAX_LENGTH = 30\n",
    "question_padded = pad_sequences(question_sequence, \n",
    "                                maxlen=MAX_LENGTH, \n",
    "                                truncating='post', \n",
    "                                padding='post')\n",
    "answer_in_padded = pad_sequences(answer_in_sequence, \n",
    "                                 maxlen=MAX_LENGTH, \n",
    "                                 truncating='post', \n",
    "                                 padding='post')\n",
    "answer_out_padded = pad_sequences(answer_out_sequence, \n",
    "                                  maxlen=MAX_LENGTH, \n",
    "                                  truncating='post', \n",
    "                                  padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e22584ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2001, 30), (2001, 30), (2001, 30))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_padded.shape, answer_in_padded.shape, answer_out_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85920dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1e825ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ce18c",
   "metadata": {},
   "source": [
    "### 인코더 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c3e0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, \n",
    "                                   embedding_dim, \n",
    "                                   input_length=time_steps)\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.lstm = LSTM(units, return_state=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden_state, cell_state = self.lstm(x)\n",
    "        return [hidden_state, cell_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260bfb6",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d66563cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, \n",
    "                                   embedding_dim, \n",
    "                                   input_length=time_steps)\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.lstm = LSTM(units, \n",
    "                         return_state=True, \n",
    "                         return_sequences=True, \n",
    "                        )\n",
    "        self.dense = Dense(vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs, initial_state):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)        \n",
    "        x = self.dense(x)\n",
    "        return x, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78317ed0",
   "metadata": {},
   "source": [
    "### 모델을 결합해서 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70a06339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 결합\n",
    "class Seq2Seq(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.time_steps = time_steps\n",
    "        \n",
    "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
    "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        if training:\n",
    "            encoder_inputs, decoder_inputs = inputs\n",
    "            context_vector = self.encoder(encoder_inputs)\n",
    "            decoder_outputs, _, _ = self.decoder(inputs=decoder_inputs, \n",
    "                                                 initial_state=context_vector)\n",
    "            return decoder_outputs\n",
    "        else:\n",
    "            context_vector = self.encoder(inputs)\n",
    "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
    "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
    "            \n",
    "            for i in tf.range(self.time_steps):\n",
    "                decoder_output, decoder_hidden, decoder_cell = self.decoder(target_seq, \n",
    "                                                                            initial_state=context_vector)\n",
    "                decoder_output = tf.cast(tf.argmax(decoder_output, axis=-1), \n",
    "                                         dtype=tf.int32)\n",
    "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
    "                results = results.write(i, decoder_output)\n",
    "                \n",
    "                if decoder_output == self.end_token:\n",
    "                    break\n",
    "                    \n",
    "                target_seq = decoder_output\n",
    "                context_vector = [decoder_hidden, decoder_cell]\n",
    "                \n",
    "            return tf.reshape(results.stack(), shape=(1, self.time_steps))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d2697",
   "metadata": {},
   "source": [
    "### 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4a4c813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 3605), (30, 3605))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
    "\n",
    "def convert_to_one_hot(padded):\n",
    "    # 원핫인코딩 초기화\n",
    "    one_hot_vector = np.zeros((len(answer_out_padded), \n",
    "                               MAX_LENGTH, \n",
    "                               VOCAB_SIZE))\n",
    "\n",
    "    # 디코더 목표를 원핫인코딩으로 변환\n",
    "    # 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "    for i, sequence in enumerate(answer_out_padded):\n",
    "        for j, index in enumerate(sequence):\n",
    "            one_hot_vector[i, j, index] = 1\n",
    "\n",
    "    return one_hot_vector\n",
    "\n",
    "answer_in_one_hot = convert_to_one_hot(answer_in_padded)\n",
    "answer_out_one_hot = convert_to_one_hot(answer_out_padded)\n",
    "answer_in_one_hot[0].shape, answer_in_one_hot[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad57b29",
   "metadata": {},
   "source": [
    "### 숫자를 문자열로 변환해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df1e6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 index를 다시 단어로 변환\n",
    "def convert_index_to_text(indexs, end_token): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == end_token:\n",
    "            # 끝 단어이므로 예측 중비\n",
    "            break;\n",
    "        # 사전에 존재하는 단어의 경우 단어 추가\n",
    "        if index > 0 and tokenizer.index_word[index] is not None:\n",
    "            sentence += tokenizer.index_word[index]\n",
    "        else:\n",
    "        # 사전에 없는 인덱스면 빈 문자열 추가\n",
    "            sentence += ''\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fb5ab",
   "metadata": {},
   "source": [
    "### 학습에 필요한 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "02471f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 100\n",
    "TIME_STEPS = MAX_LENGTH\n",
    "START_TOKEN = tokenizer.word_index['<START>']\n",
    "END_TOKEN = tokenizer.word_index['<END>']\n",
    "\n",
    "UNITS = 128\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
    "DATA_LENGTH = len(questions)\n",
    "SAMPLE_SIZE = 3\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8f656",
   "metadata": {},
   "source": [
    "### 저장을 위한 체크 포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b915e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model/seq2seq-chatbot-no-attention-checkpoint.ckpt'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True, \n",
    "                             monitor='loss', \n",
    "                             verbose=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5094a9",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe13cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq\n",
    "seq2seq = Seq2Seq(UNITS, \n",
    "                  VOCAB_SIZE, \n",
    "                  EMBEDDING_DIM, \n",
    "                  TIME_STEPS, \n",
    "                  START_TOKEN, \n",
    "                  END_TOKEN)\n",
    "\n",
    "seq2seq.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc656bcd",
   "metadata": {},
   "source": [
    "### 질문 입력 데이터를 입력하여 문장을 예측하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7afff217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, question_inputs):\n",
    "    results = model(inputs=question_inputs, training=False)\n",
    "    # 변환된 인덱스를 문장으로 변환\n",
    "    results = np.asarray(results).reshape(-1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f28ece",
   "metadata": {},
   "source": [
    "### 모델 훈련 - 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2771b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing epoch: 1...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 12s 53ms/step - loss: 2.4672 - acc: 0.7918\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.46724, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 1.1933 - acc: 0.8210\n",
      "\n",
      "Epoch 00002: loss improved from 2.46724 to 1.19325, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.1046 - acc: 0.8375\n",
      "\n",
      "Epoch 00003: loss improved from 1.19325 to 1.10457, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 1.0548 - acc: 0.8400\n",
      "\n",
      "Epoch 00004: loss improved from 1.10457 to 1.05484, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 1.0204 - acc: 0.8411\n",
      "\n",
      "Epoch 00005: loss improved from 1.05484 to 1.02039, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.9922 - acc: 0.8434\n",
      "\n",
      "Epoch 00006: loss improved from 1.02039 to 0.99225, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.9674 - acc: 0.8459\n",
      "\n",
      "Epoch 00007: loss improved from 0.99225 to 0.96743, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.9448 - acc: 0.8469\n",
      "\n",
      "Epoch 00008: loss improved from 0.96743 to 0.94480, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.9245 - acc: 0.8482\n",
      "\n",
      "Epoch 00009: loss improved from 0.94480 to 0.92446, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.9056 - acc: 0.8496\n",
      "\n",
      "Epoch 00010: loss improved from 0.92446 to 0.90564, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 더 이상 안 왔으면 좋겠어\n",
      "A: 저 을 더 더 해보세요 \n",
      "\n",
      "\n",
      "Q: 머리 하나 도 안 남 을 것 같아\n",
      "A: 저 을 더 해보세요 \n",
      "\n",
      "\n",
      "Q: 가끔 뭐 하는지 궁금해\n",
      "A: 저 을 해보세요 \n",
      "\n",
      "\n",
      "processing epoch: 11...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.8877 - acc: 0.8508\n",
      "\n",
      "Epoch 00001: loss improved from 0.90564 to 0.88768, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.8712 - acc: 0.8518\n",
      "\n",
      "Epoch 00002: loss improved from 0.88768 to 0.87117, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.8549 - acc: 0.8533\n",
      "\n",
      "Epoch 00003: loss improved from 0.87117 to 0.85491, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.8388 - acc: 0.8550\n",
      "\n",
      "Epoch 00004: loss improved from 0.85491 to 0.83876, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.8216 - acc: 0.8565\n",
      "\n",
      "Epoch 00005: loss improved from 0.83876 to 0.82156, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.8040 - acc: 0.8593\n",
      "\n",
      "Epoch 00006: loss improved from 0.82156 to 0.80400, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.7857 - acc: 0.8612\n",
      "\n",
      "Epoch 00007: loss improved from 0.80400 to 0.78573, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.7696 - acc: 0.8636\n",
      "\n",
      "Epoch 00008: loss improved from 0.78573 to 0.76961, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.7488 - acc: 0.8659\n",
      "\n",
      "Epoch 00009: loss improved from 0.76961 to 0.74881, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.7299 - acc: 0.8687\n",
      "\n",
      "Epoch 00010: loss improved from 0.74881 to 0.72986, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 만나면 싸워\n",
      "A: 저 도 있으면 사람 이 있어요 \n",
      "\n",
      "\n",
      "Q: 긴 머리 관리 어렵다\n",
      "A: 저 도 궁금하네요 \n",
      "\n",
      "\n",
      "Q: 긴장 푸는 법 알려줘\n",
      "A: 저 도 궁금하네요 \n",
      "\n",
      "\n",
      "processing epoch: 21...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.7103 - acc: 0.8716\n",
      "\n",
      "Epoch 00001: loss improved from 0.72986 to 0.71030, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.6901 - acc: 0.8742\n",
      "\n",
      "Epoch 00002: loss improved from 0.71030 to 0.69014, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.6713 - acc: 0.8773\n",
      "\n",
      "Epoch 00003: loss improved from 0.69014 to 0.67129, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.6520 - acc: 0.8803\n",
      "\n",
      "Epoch 00004: loss improved from 0.67129 to 0.65199, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.6340 - acc: 0.8831\n",
      "\n",
      "Epoch 00005: loss improved from 0.65199 to 0.63397, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.6152 - acc: 0.8859\n",
      "\n",
      "Epoch 00006: loss improved from 0.63397 to 0.61520, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.5962 - acc: 0.8897\n",
      "\n",
      "Epoch 00007: loss improved from 0.61520 to 0.59616, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.5790 - acc: 0.8921\n",
      "\n",
      "Epoch 00008: loss improved from 0.59616 to 0.57902, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.5606 - acc: 0.8957\n",
      "\n",
      "Epoch 00009: loss improved from 0.57902 to 0.56058, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.5425 - acc: 0.8984\n",
      "\n",
      "Epoch 00010: loss improved from 0.56058 to 0.54246, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 다른 사람 의 시선 이 너무 신경 쓰여\n",
      "A: 잘 할 수 있을 거 예요 \n",
      "\n",
      "\n",
      "Q: 나 빼고 다 행복한 거 같아\n",
      "A: 저 도 듣고 싶네요 \n",
      "\n",
      "\n",
      "Q: 내 가 질린대\n",
      "A: 저 도 듣고 싶네요 \n",
      "\n",
      "\n",
      "processing epoch: 31...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.5256 - acc: 0.9030\n",
      "\n",
      "Epoch 00001: loss improved from 0.54246 to 0.52560, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.5092 - acc: 0.9060\n",
      "\n",
      "Epoch 00002: loss improved from 0.52560 to 0.50917, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.4938 - acc: 0.9094\n",
      "\n",
      "Epoch 00003: loss improved from 0.50917 to 0.49382, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.4787 - acc: 0.9123\n",
      "\n",
      "Epoch 00004: loss improved from 0.49382 to 0.47868, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.4650 - acc: 0.9148\n",
      "\n",
      "Epoch 00005: loss improved from 0.47868 to 0.46498, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.4519 - acc: 0.9176\n",
      "\n",
      "Epoch 00006: loss improved from 0.46498 to 0.45193, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 6s 47ms/step - loss: 0.4393 - acc: 0.9206\n",
      "\n",
      "Epoch 00007: loss improved from 0.45193 to 0.43933, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.4268 - acc: 0.9230\n",
      "\n",
      "Epoch 00008: loss improved from 0.43933 to 0.42679, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.4150 - acc: 0.9255\n",
      "\n",
      "Epoch 00009: loss improved from 0.42679 to 0.41497, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.4036 - acc: 0.9276\n",
      "\n",
      "Epoch 00010: loss improved from 0.41497 to 0.40359, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 과일 먹고 자야지\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "Q: 근사한 곳 알 아 냈어\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "Q: 낚시 좋아하는 남자 어때\n",
      "A: 잘 할 수 있을 거 예요 \n",
      "\n",
      "\n",
      "processing epoch: 41...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.3940 - acc: 0.9292\n",
      "\n",
      "Epoch 00001: loss improved from 0.40359 to 0.39402, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3838 - acc: 0.9314\n",
      "\n",
      "Epoch 00002: loss improved from 0.39402 to 0.38383, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3748 - acc: 0.9333\n",
      "\n",
      "Epoch 00003: loss improved from 0.38383 to 0.37479, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3715 - acc: 0.9333\n",
      "\n",
      "Epoch 00004: loss improved from 0.37479 to 0.37150, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3583 - acc: 0.9353\n",
      "\n",
      "Epoch 00005: loss improved from 0.37150 to 0.35832, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3501 - acc: 0.9370\n",
      "\n",
      "Epoch 00006: loss improved from 0.35832 to 0.35011, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.3423 - acc: 0.9385\n",
      "\n",
      "Epoch 00007: loss improved from 0.35011 to 0.34231, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.3354 - acc: 0.9396\n",
      "\n",
      "Epoch 00008: loss improved from 0.34231 to 0.33536, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.3298 - acc: 0.9395\n",
      "\n",
      "Epoch 00009: loss improved from 0.33536 to 0.32981, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3237 - acc: 0.9410\n",
      "\n",
      "Epoch 00010: loss improved from 0.32981 to 0.32368, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 돈 없어도 갈 수 있는 데이트 코스\n",
      "A: 저 도 요 \n",
      "\n",
      "\n",
      "Q: 걸레질 도 해야 돼\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "Q: 더 이상 안 왔으면 좋겠어\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "processing epoch: 51...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.3172 - acc: 0.9424\n",
      "\n",
      "Epoch 00001: loss improved from 0.32368 to 0.31719, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.3119 - acc: 0.9434\n",
      "\n",
      "Epoch 00002: loss improved from 0.31719 to 0.31193, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.3066 - acc: 0.9441\n",
      "\n",
      "Epoch 00003: loss improved from 0.31193 to 0.30659, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.3022 - acc: 0.9447\n",
      "\n",
      "Epoch 00004: loss improved from 0.30659 to 0.30223, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2976 - acc: 0.9459\n",
      "\n",
      "Epoch 00005: loss improved from 0.30223 to 0.29764, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2928 - acc: 0.9464\n",
      "\n",
      "Epoch 00006: loss improved from 0.29764 to 0.29279, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2889 - acc: 0.9470\n",
      "\n",
      "Epoch 00007: loss improved from 0.29279 to 0.28890, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2848 - acc: 0.9475\n",
      "\n",
      "Epoch 00008: loss improved from 0.28890 to 0.28477, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2814 - acc: 0.9485\n",
      "\n",
      "Epoch 00009: loss improved from 0.28477 to 0.28136, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 44ms/step - loss: 0.2771 - acc: 0.9493\n",
      "\n",
      "Epoch 00010: loss improved from 0.28136 to 0.27709, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 미운 짓 만 해\n",
      "A: 지금 도 충분히 아름다워요 \n",
      "\n",
      "\n",
      "Q: 나 한테 너무 많은 걸 바라는 듯\n",
      "A: 제 가 있잖아요 \n",
      "\n",
      "\n",
      "Q: 나 맨날 속 는 거 같아\n",
      "A: 지금 도 충분히 아름다워요 \n",
      "\n",
      "\n",
      "processing epoch: 61...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2730 - acc: 0.9492\n",
      "\n",
      "Epoch 00001: loss improved from 0.27709 to 0.27301, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2711 - acc: 0.9500\n",
      "\n",
      "Epoch 00002: loss improved from 0.27301 to 0.27112, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2674 - acc: 0.9505\n",
      "\n",
      "Epoch 00003: loss improved from 0.27112 to 0.26742, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2647 - acc: 0.9510\n",
      "\n",
      "Epoch 00004: loss improved from 0.26742 to 0.26471, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 5s 44ms/step - loss: 0.2617 - acc: 0.9513\n",
      "\n",
      "Epoch 00005: loss improved from 0.26471 to 0.26172, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2586 - acc: 0.9518\n",
      "\n",
      "Epoch 00006: loss improved from 0.26172 to 0.25859, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 5s 44ms/step - loss: 0.2559 - acc: 0.9520\n",
      "\n",
      "Epoch 00007: loss improved from 0.25859 to 0.25594, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2532 - acc: 0.9524\n",
      "\n",
      "Epoch 00008: loss improved from 0.25594 to 0.25322, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2511 - acc: 0.9525\n",
      "\n",
      "Epoch 00009: loss improved from 0.25322 to 0.25110, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2486 - acc: 0.9531\n",
      "\n",
      "Epoch 00010: loss improved from 0.25110 to 0.24858, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 머릿속 이 하얘졌어\n",
      "A: 저 도 궁금하네요 \n",
      "\n",
      "\n",
      "Q: 뭐 야 너무 건방져\n",
      "A: 저 도 궁금하네요 \n",
      "\n",
      "\n",
      "Q: 돈 모으는 재미 가 있네\n",
      "A: 지금 도 충분히 아름다워요 \n",
      "\n",
      "\n",
      "processing epoch: 71...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2463 - acc: 0.9533\n",
      "\n",
      "Epoch 00001: loss improved from 0.24858 to 0.24627, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2441 - acc: 0.9534\n",
      "\n",
      "Epoch 00002: loss improved from 0.24627 to 0.24410, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2421 - acc: 0.9543\n",
      "\n",
      "Epoch 00003: loss improved from 0.24410 to 0.24214, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2402 - acc: 0.9539\n",
      "\n",
      "Epoch 00004: loss improved from 0.24214 to 0.24015, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2383 - acc: 0.9541\n",
      "\n",
      "Epoch 00005: loss improved from 0.24015 to 0.23828, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2371 - acc: 0.9546\n",
      "\n",
      "Epoch 00006: loss improved from 0.23828 to 0.23707, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2349 - acc: 0.9548\n",
      "\n",
      "Epoch 00007: loss improved from 0.23707 to 0.23494, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2340 - acc: 0.9544\n",
      "\n",
      "Epoch 00008: loss improved from 0.23494 to 0.23404, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2310 - acc: 0.9552\n",
      "\n",
      "Epoch 00009: loss improved from 0.23404 to 0.23099, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2287 - acc: 0.9557\n",
      "\n",
      "Epoch 00010: loss improved from 0.23099 to 0.22869, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 궁금해 알려줘\n",
      "A: 지금 도 충분히 아름다워요 \n",
      "\n",
      "\n",
      "Q: 가스 비 너무 많이 나왔다\n",
      "A: 제 가 있잖아요 \n",
      "\n",
      "\n",
      "Q: 눈 이 안 떠져\n",
      "A: 지금 도 충분히 아름다워요 \n",
      "\n",
      "\n",
      "processing epoch: 81...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2292 - acc: 0.9552\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.22869\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2254 - acc: 0.9563\n",
      "\n",
      "Epoch 00002: loss improved from 0.22869 to 0.22541, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2243 - acc: 0.9563\n",
      "\n",
      "Epoch 00003: loss improved from 0.22541 to 0.22426, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2231 - acc: 0.9557\n",
      "\n",
      "Epoch 00004: loss improved from 0.22426 to 0.22309, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.2216 - acc: 0.9566\n",
      "\n",
      "Epoch 00005: loss improved from 0.22309 to 0.22156, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2200 - acc: 0.9563\n",
      "\n",
      "Epoch 00006: loss improved from 0.22156 to 0.22004, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.2189 - acc: 0.9568\n",
      "\n",
      "Epoch 00007: loss improved from 0.22004 to 0.21886, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2173 - acc: 0.9570\n",
      "\n",
      "Epoch 00008: loss improved from 0.21886 to 0.21735, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2164 - acc: 0.9570\n",
      "\n",
      "Epoch 00009: loss improved from 0.21735 to 0.21641, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.2160 - acc: 0.9569\n",
      "\n",
      "Epoch 00010: loss improved from 0.21641 to 0.21596, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 더 이상 안 왔으면 좋겠어\n",
      "A: 저 도 보고 싶어요 \n",
      "\n",
      "\n",
      "Q: 나 만 애기 봐\n",
      "A: 저 도 보고 싶어요 \n",
      "\n",
      "\n",
      "Q: 나 다른 거 할까\n",
      "A: 저 도 보고 싶어요 \n",
      "\n",
      "\n",
      "processing epoch: 91...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2141 - acc: 0.9573\n",
      "\n",
      "Epoch 00001: loss improved from 0.21596 to 0.21411, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2148 - acc: 0.9572\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.21411\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2119 - acc: 0.9577\n",
      "\n",
      "Epoch 00003: loss improved from 0.21411 to 0.21187, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.2099 - acc: 0.9581\n",
      "\n",
      "Epoch 00004: loss improved from 0.21187 to 0.20993, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.2086 - acc: 0.9579\n",
      "\n",
      "Epoch 00005: loss improved from 0.20993 to 0.20860, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2078 - acc: 0.9580\n",
      "\n",
      "Epoch 00006: loss improved from 0.20860 to 0.20782, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.2073 - acc: 0.9580\n",
      "\n",
      "Epoch 00007: loss improved from 0.20782 to 0.20734, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.2068 - acc: 0.9580\n",
      "\n",
      "Epoch 00008: loss improved from 0.20734 to 0.20678, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2069 - acc: 0.9585\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.20678\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2032 - acc: 0.9587\n",
      "\n",
      "Epoch 00010: loss improved from 0.20678 to 0.20320, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 더 이상 나 한테 안 왔으면 좋겠어\n",
      "A: 저 도 보고 싶어요 \n",
      "\n",
      "\n",
      "Q: 머리 가 좀 아프다\n",
      "A: 눈 을 깜빡 거려 보세요 \n",
      "\n",
      "\n",
      "Q: 나 열심히 할거야\n",
      "A: 잠시 눈 을 붙 여보세요 \n",
      "\n",
      "\n",
      "processing epoch: 101...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2026 - acc: 0.9587\n",
      "\n",
      "Epoch 00001: loss improved from 0.20320 to 0.20256, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2011 - acc: 0.9587\n",
      "\n",
      "Epoch 00002: loss improved from 0.20256 to 0.20113, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2007 - acc: 0.9582\n",
      "\n",
      "Epoch 00003: loss improved from 0.20113 to 0.20070, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1978 - acc: 0.9591\n",
      "\n",
      "Epoch 00004: loss improved from 0.20070 to 0.19783, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1961 - acc: 0.9592\n",
      "\n",
      "Epoch 00005: loss improved from 0.19783 to 0.19606, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1949 - acc: 0.9595\n",
      "\n",
      "Epoch 00006: loss improved from 0.19606 to 0.19490, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1959 - acc: 0.9591\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.19490\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1943 - acc: 0.9593\n",
      "\n",
      "Epoch 00008: loss improved from 0.19490 to 0.19430, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1914 - acc: 0.9596\n",
      "\n",
      "Epoch 00009: loss improved from 0.19430 to 0.19136, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1901 - acc: 0.9594\n",
      "\n",
      "Epoch 00010: loss improved from 0.19136 to 0.19010, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 면허 따는 중\n",
      "A: 지금 도 충분히 아름다워요 \n",
      "\n",
      "\n",
      "Q: 면접 준비 어떻게 하지\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "Q: 등록금 비싸다\n",
      "A: 맛있게 드세요 \n",
      "\n",
      "\n",
      "processing epoch: 111...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1873 - acc: 0.9602\n",
      "\n",
      "Epoch 00001: loss improved from 0.19010 to 0.18730, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1862 - acc: 0.9600\n",
      "\n",
      "Epoch 00002: loss improved from 0.18730 to 0.18621, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1846 - acc: 0.9606\n",
      "\n",
      "Epoch 00003: loss improved from 0.18621 to 0.18455, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1830 - acc: 0.9605\n",
      "\n",
      "Epoch 00004: loss improved from 0.18455 to 0.18297, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1817 - acc: 0.9606\n",
      "\n",
      "Epoch 00005: loss improved from 0.18297 to 0.18167, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1807 - acc: 0.9606\n",
      "\n",
      "Epoch 00006: loss improved from 0.18167 to 0.18074, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1797 - acc: 0.9610\n",
      "\n",
      "Epoch 00007: loss improved from 0.18074 to 0.17967, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1778 - acc: 0.9613\n",
      "\n",
      "Epoch 00008: loss improved from 0.17967 to 0.17776, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1774 - acc: 0.9607\n",
      "\n",
      "Epoch 00009: loss improved from 0.17776 to 0.17737, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1756 - acc: 0.9611\n",
      "\n",
      "Epoch 00010: loss improved from 0.17737 to 0.17561, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 기대 가 무너졌어\n",
      "A: 자책 하지 마세요 \n",
      "\n",
      "\n",
      "Q: 뭐 가 잘 못 된 걸까\n",
      "A: 제 가 생각 해도 저 는 사람 만나세요 \n",
      "\n",
      "\n",
      "Q: 노래방 걸 거 같은데 뭐 부르지\n",
      "A: 마음 에 드는 걸 로 하세요 \n",
      "\n",
      "\n",
      "processing epoch: 121...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1752 - acc: 0.9613\n",
      "\n",
      "Epoch 00001: loss improved from 0.17561 to 0.17524, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1742 - acc: 0.9615\n",
      "\n",
      "Epoch 00002: loss improved from 0.17524 to 0.17424, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1713 - acc: 0.9616\n",
      "\n",
      "Epoch 00003: loss improved from 0.17424 to 0.17132, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 5s 44ms/step - loss: 0.1708 - acc: 0.9616\n",
      "\n",
      "Epoch 00004: loss improved from 0.17132 to 0.17082, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1693 - acc: 0.9624\n",
      "\n",
      "Epoch 00005: loss improved from 0.17082 to 0.16927, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1676 - acc: 0.9621\n",
      "\n",
      "Epoch 00006: loss improved from 0.16927 to 0.16758, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1659 - acc: 0.9627\n",
      "\n",
      "Epoch 00007: loss improved from 0.16758 to 0.16595, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1645 - acc: 0.9624\n",
      "\n",
      "Epoch 00008: loss improved from 0.16595 to 0.16451, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1653 - acc: 0.9628\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.16451\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1618 - acc: 0.9630\n",
      "\n",
      "Epoch 00010: loss improved from 0.16451 to 0.16183, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 너무 많은 걸 바 래\n",
      "A: 좋은 결과 있을 거 예요 \n",
      "\n",
      "\n",
      "Q: 너무 힘들다 지쳤어\n",
      "A: 잠시 눈 을 감고 휴식 을 취 해보세요 \n",
      "\n",
      "\n",
      "Q: 마음 에 하나 도 안 들어\n",
      "A: 마음 에 들면 줘 보세요 \n",
      "\n",
      "\n",
      "processing epoch: 131...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1597 - acc: 0.9630\n",
      "\n",
      "Epoch 00001: loss improved from 0.16183 to 0.15967, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1591 - acc: 0.9635\n",
      "\n",
      "Epoch 00002: loss improved from 0.15967 to 0.15912, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1574 - acc: 0.9637\n",
      "\n",
      "Epoch 00003: loss improved from 0.15912 to 0.15743, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1552 - acc: 0.9636\n",
      "\n",
      "Epoch 00004: loss improved from 0.15743 to 0.15525, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1533 - acc: 0.9638\n",
      "\n",
      "Epoch 00005: loss improved from 0.15525 to 0.15334, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1515 - acc: 0.9643\n",
      "\n",
      "Epoch 00006: loss improved from 0.15334 to 0.15146, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1529 - acc: 0.9641\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.15146\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1515 - acc: 0.9641\n",
      "\n",
      "Epoch 00008: loss improved from 0.15146 to 0.15146, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1483 - acc: 0.9646\n",
      "\n",
      "Epoch 00009: loss improved from 0.15146 to 0.14829, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1459 - acc: 0.9655\n",
      "\n",
      "Epoch 00010: loss improved from 0.14829 to 0.14592, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 배 가 너무 고파\n",
      "A: 저 도 듣고 싶네요 \n",
      "\n",
      "\n",
      "Q: 대리 운전 불렀어\n",
      "A: 잘 하고 있어요 당당해지세요 \n",
      "\n",
      "\n",
      "Q: 나 할 수 있어\n",
      "A: 저 도 궁금하네요 \n",
      "\n",
      "\n",
      "processing epoch: 141...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1446 - acc: 0.9651\n",
      "\n",
      "Epoch 00001: loss improved from 0.14592 to 0.14464, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1440 - acc: 0.9653\n",
      "\n",
      "Epoch 00002: loss improved from 0.14464 to 0.14401, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1419 - acc: 0.9655\n",
      "\n",
      "Epoch 00003: loss improved from 0.14401 to 0.14191, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1415 - acc: 0.9656\n",
      "\n",
      "Epoch 00004: loss improved from 0.14191 to 0.14153, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 5s 44ms/step - loss: 0.1405 - acc: 0.9658\n",
      "\n",
      "Epoch 00005: loss improved from 0.14153 to 0.14049, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1406 - acc: 0.9654\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.14049\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1375 - acc: 0.9663\n",
      "\n",
      "Epoch 00007: loss improved from 0.14049 to 0.13749, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1360 - acc: 0.9666\n",
      "\n",
      "Epoch 00008: loss improved from 0.13749 to 0.13600, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1360 - acc: 0.9662\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.13600\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1331 - acc: 0.9669\n",
      "\n",
      "Epoch 00010: loss improved from 0.13600 to 0.13312, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 나 백수 야\n",
      "A: 저 는 위로 봇 입니다 \n",
      "\n",
      "\n",
      "Q: 먹고 죽 을 돈 도 없어\n",
      "A: 저 는 위로 봇 입니다 \n",
      "\n",
      "\n",
      "Q: 남자친구 교회 데려가고 싶어\n",
      "A: 많이 지쳤나 봐요 \n",
      "\n",
      "\n",
      "processing epoch: 151...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1310 - acc: 0.9671\n",
      "\n",
      "Epoch 00001: loss improved from 0.13312 to 0.13102, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1305 - acc: 0.9668\n",
      "\n",
      "Epoch 00002: loss improved from 0.13102 to 0.13046, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1297 - acc: 0.9667\n",
      "\n",
      "Epoch 00003: loss improved from 0.13046 to 0.12970, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1285 - acc: 0.9671\n",
      "\n",
      "Epoch 00004: loss improved from 0.12970 to 0.12846, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1282 - acc: 0.9668\n",
      "\n",
      "Epoch 00005: loss improved from 0.12846 to 0.12819, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1272 - acc: 0.9673\n",
      "\n",
      "Epoch 00006: loss improved from 0.12819 to 0.12719, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1269 - acc: 0.9677\n",
      "\n",
      "Epoch 00007: loss improved from 0.12719 to 0.12693, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1255 - acc: 0.9681\n",
      "\n",
      "Epoch 00008: loss improved from 0.12693 to 0.12547, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1240 - acc: 0.9682\n",
      "\n",
      "Epoch 00009: loss improved from 0.12547 to 0.12404, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1207 - acc: 0.9687\n",
      "\n",
      "Epoch 00010: loss improved from 0.12404 to 0.12071, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 내일 클스 마스 이브 네\n",
      "A: 메리 크리스마스 \n",
      "\n",
      "\n",
      "Q: 걔 는 누굴 닮아서 그런거니\n",
      "A: 당신 이 요 \n",
      "\n",
      "\n",
      "Q: 드디어 해외 여행 간다\n",
      "A: 연예인 을 준비 하니 일반인 보다 다 예쁘겠죠 \n",
      "\n",
      "\n",
      "processing epoch: 161...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1217 - acc: 0.9681\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.12071\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1214 - acc: 0.9686\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.12071\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1194 - acc: 0.9687\n",
      "\n",
      "Epoch 00003: loss improved from 0.12071 to 0.11941, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1200 - acc: 0.9686\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.11941\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1176 - acc: 0.9695\n",
      "\n",
      "Epoch 00005: loss improved from 0.11941 to 0.11759, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1149 - acc: 0.9696\n",
      "\n",
      "Epoch 00006: loss improved from 0.11759 to 0.11489, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1124 - acc: 0.9702\n",
      "\n",
      "Epoch 00007: loss improved from 0.11489 to 0.11244, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1113 - acc: 0.9706\n",
      "\n",
      "Epoch 00008: loss improved from 0.11244 to 0.11126, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1101 - acc: 0.9710\n",
      "\n",
      "Epoch 00009: loss improved from 0.11126 to 0.11008, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1136 - acc: 0.9701\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.11008\n",
      "Q: 레시피 대로 했는데 왜 맛 이 없지\n",
      "A: 가장 중요한 목표 네 요 \n",
      "\n",
      "\n",
      "Q: 바 본가 봐\n",
      "A: 바보 는 자기 한테 바보 라고 하지 않아요 \n",
      "\n",
      "\n",
      "Q: 목 이 뻑뻑 해\n",
      "A: 따뜻해졌죠 \n",
      "\n",
      "\n",
      "processing epoch: 171...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1096 - acc: 0.9707\n",
      "\n",
      "Epoch 00001: loss improved from 0.11008 to 0.10962, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1070 - acc: 0.9716\n",
      "\n",
      "Epoch 00002: loss improved from 0.10962 to 0.10704, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1072 - acc: 0.9712\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.10704\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1085 - acc: 0.9712\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.10704\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1040 - acc: 0.9720\n",
      "\n",
      "Epoch 00005: loss improved from 0.10704 to 0.10400, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1034 - acc: 0.9722\n",
      "\n",
      "Epoch 00006: loss improved from 0.10400 to 0.10341, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1019 - acc: 0.9727\n",
      "\n",
      "Epoch 00007: loss improved from 0.10341 to 0.10193, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1025 - acc: 0.9724\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.10193\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1001 - acc: 0.9730\n",
      "\n",
      "Epoch 00009: loss improved from 0.10193 to 0.10010, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.0972 - acc: 0.9736\n",
      "\n",
      "Epoch 00010: loss improved from 0.10010 to 0.09722, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 동생 이랑 대판 싸움\n",
      "A: 메리 크리스마스 \n",
      "\n",
      "\n",
      "Q: 대리 님 은 갈구는게 취미 인 듯\n",
      "A: 자신 과 대화 하는 시간 이 필요하죠 \n",
      "\n",
      "\n",
      "Q: 기본 이 뭔 지도 모르는 것 같아\n",
      "A: 모르는 게 잘못 인 거 같아요 \n",
      "\n",
      "\n",
      "processing epoch: 181...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.0969 - acc: 0.9737\n",
      "\n",
      "Epoch 00001: loss improved from 0.09722 to 0.09688, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.0941 - acc: 0.9740\n",
      "\n",
      "Epoch 00002: loss improved from 0.09688 to 0.09408, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.0936 - acc: 0.9745\n",
      "\n",
      "Epoch 00003: loss improved from 0.09408 to 0.09356, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.0928 - acc: 0.9745\n",
      "\n",
      "Epoch 00004: loss improved from 0.09356 to 0.09281, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.0921 - acc: 0.9744\n",
      "\n",
      "Epoch 00005: loss improved from 0.09281 to 0.09212, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.0905 - acc: 0.9750\n",
      "\n",
      "Epoch 00006: loss improved from 0.09212 to 0.09052, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.0905 - acc: 0.9753\n",
      "\n",
      "Epoch 00007: loss improved from 0.09052 to 0.09047, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.0869 - acc: 0.9759\n",
      "\n",
      "Epoch 00008: loss improved from 0.09047 to 0.08687, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.0864 - acc: 0.9759\n",
      "\n",
      "Epoch 00009: loss improved from 0.08687 to 0.08642, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.0838 - acc: 0.9758\n",
      "\n",
      "Epoch 00010: loss improved from 0.08642 to 0.08376, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 나 그동안 뭐 한거니\n",
      "A: 그런 생각 을 들게 하는 사람 상종 하지 마세요 \n",
      "\n",
      "\n",
      "Q: 날씨 가 너무 추워\n",
      "A: 로맨틱 하네요 \n",
      "\n",
      "\n",
      "Q: 가족 여행 가야 지\n",
      "A: 좋은 만남이었길 바라요 \n",
      "\n",
      "\n",
      "processing epoch: 191...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.0829 - acc: 0.9772\n",
      "\n",
      "Epoch 00001: loss improved from 0.08376 to 0.08288, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.0827 - acc: 0.9768\n",
      "\n",
      "Epoch 00002: loss improved from 0.08288 to 0.08270, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.0814 - acc: 0.9774\n",
      "\n",
      "Epoch 00003: loss improved from 0.08270 to 0.08136, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.0808 - acc: 0.9776\n",
      "\n",
      "Epoch 00004: loss improved from 0.08136 to 0.08082, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.0787 - acc: 0.9782\n",
      "\n",
      "Epoch 00005: loss improved from 0.08082 to 0.07867, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.0791 - acc: 0.9778\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.07867\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.0775 - acc: 0.9783\n",
      "\n",
      "Epoch 00007: loss improved from 0.07867 to 0.07751, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.0762 - acc: 0.9784\n",
      "\n",
      "Epoch 00008: loss improved from 0.07751 to 0.07622, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.0747 - acc: 0.9790\n",
      "\n",
      "Epoch 00009: loss improved from 0.07622 to 0.07473, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.0732 - acc: 0.9795\n",
      "\n",
      "Epoch 00010: loss improved from 0.07473 to 0.07319, saving model to model/seq2seq-chatbot-no-attention-checkpoint.ckpt\n",
      "Q: 나 무시 당한 거 같아\n",
      "A: 그런 생각 을 들게 하는 사람 상종 하지 마세요 \n",
      "\n",
      "\n",
      "Q: 말투 가 맘 에 안 들어\n",
      "A: 말투 는 바꿀 수 있을 텐데 성격 이 별로 라면 문제 겠네요 \n",
      "\n",
      "\n",
      "Q: 내 가 좋아할 자격 이 있나\n",
      "A: 상종 하지 마세요 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'processing epoch: {epoch * 10 + 1}...')\n",
    "    seq2seq.fit([question_padded, answer_in_padded],\n",
    "                answer_out_one_hot,\n",
    "                epochs=10,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                callbacks=[checkpoint]\n",
    "               )\n",
    "    # 랜덤한 샘플 번호 추출\n",
    "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
    "\n",
    "    # 예측 성능 테스트\n",
    "    for idx in samples:\n",
    "        question_inputs = question_padded[idx]\n",
    "        # 문장 예측\n",
    "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
    "        \n",
    "        # 변환된 인덱스를 문장으로 변환\n",
    "        results = convert_index_to_text(results, END_TOKEN)\n",
    "        \n",
    "        print(f'Q: {questions[idx]}')\n",
    "        print(f'A: {results}\\n')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ca43b",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eaf1a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124, 170, 347,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자연어 (질문 입력) 대한 전처리 함수\n",
    "def make_question(sentence):\n",
    "    sentence = clean_and_morph(sentence)\n",
    "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "    return question_padded\n",
    "\n",
    "make_question('오늘 날씨 어때?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fef4e5",
   "metadata": {},
   "source": [
    "### 챗봇 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9c989c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< 말을 걸어 보세요!\n",
      "뭐해\n",
      ">> 챗봇 응답: 회사 와 자신 에 대해 서 더 공부 해서 자신감 을 가져 보세요 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/fxl3_n31121f16yj69fbrb_m0000gn/T/ipykernel_1277/2276560116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 챗봇 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<< 말을 걸어 보세요!\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    979\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             )\n\u001b[0;32m--> 981\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 챗봇\n",
    "def run_chatbot(question):\n",
    "    question_inputs = make_question(question)\n",
    "    results = make_prediction(seq2seq, question_inputs)\n",
    "    results = convert_index_to_text(results, END_TOKEN)\n",
    "    return results\n",
    "\n",
    "# 챗봇 실행\n",
    "while True:\n",
    "    user_input = input('<< 말을 걸어 보세요!\\n')\n",
    "    if user_input == 'q':\n",
    "        break\n",
    "    print('>> 챗봇 응답: {}'.format(run_chatbot(user_input)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e4d3db",
   "metadata": {},
   "source": [
    "## Attention을 활용한 IMDB 감성 리뷰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92c247",
   "metadata": {},
   "source": [
    "### IMDB 리뷰 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebd8252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/adam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2494\n",
      "리뷰의 평균 길이 : 238.71364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n",
    "\n",
    "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
    "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6629e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b2784",
   "metadata": {},
   "source": [
    "### Attention 메커니즘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0549a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = Dense(units)\n",
    "    self.W2 = Dense(units)\n",
    "    self.V = Dense(1)\n",
    "\n",
    "  def call(self, values, query): # 단, key와 value는 같음\n",
    "    # query shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c426f9f",
   "metadata": {},
   "source": [
    "### 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac79fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdbd52",
   "metadata": {},
   "source": [
    "### 입력 층 과 출력 층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b333fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 14:39:54.337552: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151089f",
   "metadata": {},
   "source": [
    "### 양방향 LSTM 층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d81dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7ea70",
   "metadata": {},
   "source": [
    "### 두번째 층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6800b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e66a24",
   "metadata": {},
   "source": [
    "### 각 상태의 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76f34b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
     ]
    }
   ],
   "source": [
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaee059",
   "metadata": {},
   "source": [
    "### LSTM 상태들을 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c561f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
    "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda6917",
   "metadata": {},
   "source": [
    "### 컨텍스트 벡터를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dafd8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
    "context_vector, attention_weights = attention(lstm, state_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e3a63",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2135c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
    "model = Model(inputs=sequence_input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766b453",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96582483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60113b4",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e9b19d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 14:45:06.652838: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 482s 5s/step - loss: 0.4881 - accuracy: 0.7604 - val_loss: 0.2933 - val_accuracy: 0.8790\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 523s 5s/step - loss: 0.2451 - accuracy: 0.9124 - val_loss: 0.2863 - val_accuracy: 0.8796\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 455s 5s/step - loss: 0.1880 - accuracy: 0.9376 - val_loss: 0.2930 - val_accuracy: 0.8821\n"
     ]
    }
   ],
   "source": [
    "istory = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a27fa4",
   "metadata": {},
   "source": [
    "### 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118d4391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 108s 138ms/step - loss: 0.2930 - accuracy: 0.8821\n",
      "\n",
      " 테스트 정확도: 0.8821\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39298c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b9883",
   "metadata": {},
   "source": [
    "## Attention 을 활용한 챗봇 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098aa5ab",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3206145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : songys@github\n",
      "    Repository : https://github.com/songys/Chatbot_data\n",
      "    References :\n",
      "\n",
      "    Chatbot_data_for_Korean v1.0\n",
      "      1. 챗봇 트레이닝용 문답 페어 11,876개\n",
      "      2. 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링\n",
      "    자세한 내용은 위의 repository를 참고하세요.\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `korean_chatbot_data` is already installed at /Users/adam/Korpora/korean_chatbot_data/ChatbotData.csv\n"
     ]
    }
   ],
   "source": [
    "from Korpora import KoreanChatbotKorpus\n",
    "corpus = KoreanChatbotKorpus()\n",
    "\n",
    "# 2,000개 데이터 셋만 활용 (Google Colab 일 경우 3,000개에서는 메모리 오버되는 현상 발생)\n",
    "texts = []\n",
    "pairs = []\n",
    "for i, (text, pair) in enumerate(zip(corpus.get_all_texts(), corpus.get_all_pairs())):\n",
    "    texts.append(text)\n",
    "    pairs.append(pair)\n",
    "    \n",
    "    #Colab 의 경우 아래 주석 해제 - 메모리가 부족하면 로컬에서도 해제\n",
    "    if i >= 2000: \n",
    "        break \n",
    "        \n",
    "# 데이터 전처리 함수 (정규식(regex expression)활용)\n",
    "import re\n",
    "def clean_sentence(sentence):\n",
    "    # 한글, 숫자를 제외한 모든 문자는 제거합니다.\n",
    "    sentence = re.sub(r'[^0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "def process_morph(sentence):\n",
    "    return ' '.join(okt.morphs(sentence))\n",
    "\n",
    "# 문장 전처리\n",
    "def clean_and_morph(sentence, is_question=True):\n",
    "    # 한글 문장 전처리\n",
    "    sentence = clean_sentence(sentence)\n",
    "    # 형태소 변환\n",
    "    sentence = process_morph(sentence)\n",
    "    # Question 인 경우, Answer인 경우를 분기하여 처리합니다.\n",
    "    if is_question:\n",
    "        return sentence\n",
    "    else:\n",
    "        # START 토큰은 decoder input에 END 토큰은 decoder output에 추가합니다.\n",
    "        return ('<START> ' + sentence, sentence + ' <END>')\n",
    "\n",
    "def preprocess(texts, pairs):\n",
    "    questions = []\n",
    "    answer_in = []\n",
    "    answer_out = []\n",
    "\n",
    "    # 질의에 대한 전처리\n",
    "    for text in texts:\n",
    "        # 전처리와 morph 수행\n",
    "        question = clean_and_morph(text, is_question=True)\n",
    "        questions.append(question)\n",
    "\n",
    "    # 답변에 대한 전처리\n",
    "    for pair in pairs:\n",
    "        # 전처리와 morph 수행\n",
    "        in_, out_ = clean_and_morph(pair, is_question=False)\n",
    "        answer_in.append(in_)\n",
    "        answer_out.append(out_)\n",
    "    \n",
    "    return questions, answer_in, answer_out\n",
    "\n",
    "questions, answer_in, answer_out = preprocess(texts, pairs)\n",
    "\n",
    "all_sentences = questions + answer_in + answer_out\n",
    "\n",
    "# 라이브러리 불어오기\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# WARNING 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(all_sentences)\n",
    "\n",
    "# 치환: 텍스트를 시퀀스로 인코딩 (texts_to_sequences)\n",
    "question_sequence = tokenizer.texts_to_sequences(questions)\n",
    "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
    "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)\n",
    "\n",
    "# 문장의 길이 맞추기 (pad_sequences)\n",
    "MAX_LENGTH = 30\n",
    "question_padded = pad_sequences(question_sequence, \n",
    "                                maxlen=MAX_LENGTH, \n",
    "                                truncating='post', \n",
    "                                padding='post')\n",
    "answer_in_padded = pad_sequences(answer_in_sequence, \n",
    "                                 maxlen=MAX_LENGTH, \n",
    "                                 truncating='post', \n",
    "                                 padding='post')\n",
    "answer_out_padded = pad_sequences(answer_out_sequence, \n",
    "                                  maxlen=MAX_LENGTH, \n",
    "                                  truncating='post', \n",
    "                                  padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21b5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로드\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca8562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, \n",
    "                                   embedding_dim, \n",
    "                                   input_length=time_steps, \n",
    "                                   name='Embedding')\n",
    "        self.dropout = Dropout(0.2, name='Dropout')\n",
    "        # (attention) return_sequences=True 추가\n",
    "        self.lstm = LSTM(units, \n",
    "                         return_state=True, \n",
    "                         return_sequences=True, \n",
    "                         name='LSTM')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden_state, cell_state = self.lstm(x)\n",
    "        # (attention) x return 추가\n",
    "        return x, [hidden_state, cell_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f8cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, \n",
    "                                   embedding_dim, \n",
    "                                   input_length=time_steps, \n",
    "                                   name='Embedding')\n",
    "        self.dropout = Dropout(0.2, name='Dropout')\n",
    "        self.lstm = LSTM(units, \n",
    "                         return_state=True, \n",
    "                         return_sequences=True, \n",
    "                         name='LSTM'\n",
    "                        )\n",
    "        self.attention = Attention(name='Attention')\n",
    "        self.dense = Dense(vocab_size, \n",
    "                           activation='softmax', \n",
    "                           name='Dense')\n",
    "    \n",
    "    def call(self, inputs, initial_state):\n",
    "        # (attention) encoder_inputs 추가\n",
    "        encoder_inputs, decoder_inputs = inputs\n",
    "        x = self.embedding(decoder_inputs)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
    "        \n",
    "        # (attention) key_value, attention_matrix 추가\n",
    "        # 이전 hidden_state의 값을 concat으로 만들어 vector를 생성합니다.        \n",
    "        key_value = tf.concat([initial_state[0][:, tf.newaxis, :], \n",
    "                               x[:, :-1, :]], axis=1)        \n",
    "        # 이전 hidden_state의 값을 concat으로 만든 vector와 encoder에서 나온 \n",
    "        # 출력 값들로 attention을 구합니다.\n",
    "        attention_matrix = self.attention([key_value, encoder_inputs])\n",
    "        # 위에서 구한 attention_matrix와 decoder의 출력 값을 concat 합니다.\n",
    "        x = tf.concat([x, attention_matrix], axis=-1)\n",
    "        \n",
    "        x = self.dense(x)\n",
    "        return x, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add4f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.time_steps = time_steps\n",
    "        \n",
    "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
    "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        if training:\n",
    "            encoder_inputs, decoder_inputs = inputs\n",
    "            # (attention) encoder 출력 값 수정\n",
    "            encoder_outputs, context_vector = self.encoder(encoder_inputs)\n",
    "            # (attention) decoder 입력 값 수정\n",
    "            decoder_outputs, _, _ = self.decoder((encoder_outputs, decoder_inputs), \n",
    "                                                 initial_state=context_vector)\n",
    "            return decoder_outputs\n",
    "        else:\n",
    "            x = inputs\n",
    "            # (attention) encoder 출력 값 수정\n",
    "            encoder_outputs, context_vector = self.encoder(x)\n",
    "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
    "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
    "            \n",
    "            for i in tf.range(self.time_steps):\n",
    "                decoder_output, decoder_hidden, decoder_cell = self.decoder((encoder_outputs, target_seq), \n",
    "                                                                            initial_state=context_vector)\n",
    "                decoder_output = tf.cast(tf.argmax(decoder_output, axis=-1), dtype=tf.int32)\n",
    "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
    "                results = results.write(i, decoder_output)\n",
    "                \n",
    "                if decoder_output == self.end_token:\n",
    "                    break\n",
    "                    \n",
    "                target_seq = decoder_output\n",
    "                context_vector = [decoder_hidden, decoder_cell]\n",
    "                \n",
    "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6724a",
   "metadata": {},
   "source": [
    "### 단어별 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af62c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2434176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 3605), (30, 3605))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_one_hot(padded):\n",
    "    # 원핫인코딩 초기화\n",
    "    one_hot_vector = np.zeros((len(answer_out_padded), \n",
    "                               MAX_LENGTH, \n",
    "                               VOCAB_SIZE))\n",
    "\n",
    "    # 디코더 목표를 원핫인코딩으로 변환\n",
    "    # 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "    for i, sequence in enumerate(answer_out_padded):\n",
    "        for j, index in enumerate(sequence):\n",
    "            one_hot_vector[i, j, index] = 1\n",
    "\n",
    "    return one_hot_vector\n",
    "\n",
    "answer_in_one_hot = convert_to_one_hot(answer_in_padded)\n",
    "answer_out_one_hot = convert_to_one_hot(answer_out_padded)\n",
    "answer_in_one_hot[0].shape, answer_in_one_hot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1a990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 index를 다시 단어로 변환\n",
    "def convert_index_to_text(indexs, end_token): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == end_token:\n",
    "            # 끝 단어이므로 예측 중비\n",
    "            break;\n",
    "        # 사전에 존재하는 단어의 경우 단어 추가\n",
    "        if index > 0 and tokenizer.index_word[index] is not None:\n",
    "            sentence += tokenizer.index_word[index]\n",
    "        else:\n",
    "        # 사전에 없는 인덱스면 빈 문자열 추가\n",
    "            sentence += ''\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112ad89",
   "metadata": {},
   "source": [
    "### 모델을 위한 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b378ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 100\n",
    "TIME_STEPS = MAX_LENGTH\n",
    "START_TOKEN = tokenizer.word_index['<START>']\n",
    "END_TOKEN = tokenizer.word_index['<END>']\n",
    "\n",
    "UNITS = 128\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
    "DATA_LENGTH = len(questions)\n",
    "SAMPLE_SIZE = 3\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aaf2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model/seq2seq-attention-checkpoint.ckpt'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True, \n",
    "                             monitor='loss', \n",
    "                             verbose=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da28810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 15:52:31.309340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# seq2seq\n",
    "seq2seq = Seq2Seq(UNITS, \n",
    "                  VOCAB_SIZE, \n",
    "                  EMBEDDING_DIM, \n",
    "                  TIME_STEPS, \n",
    "                  START_TOKEN, \n",
    "                  END_TOKEN)\n",
    "\n",
    "seq2seq.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2fdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, question_inputs):\n",
    "    results = model(inputs=question_inputs, training=False)\n",
    "    # 변환된 인덱스를 문장으로 변환\n",
    "    results = np.asarray(results).reshape(-1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e1c8a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing epoch: 1...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.8474 - acc: 0.8557\n",
      "\n",
      "Epoch 00001: loss improved from 0.87252 to 0.84737, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.8227 - acc: 0.8581\n",
      "\n",
      "Epoch 00002: loss improved from 0.84737 to 0.82270, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.7961 - acc: 0.8610\n",
      "\n",
      "Epoch 00003: loss improved from 0.82270 to 0.79606, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 9s 67ms/step - loss: 0.7681 - acc: 0.8636\n",
      "\n",
      "Epoch 00004: loss improved from 0.79606 to 0.76810, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.7418 - acc: 0.8665\n",
      "\n",
      "Epoch 00005: loss improved from 0.76810 to 0.74179, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.7163 - acc: 0.8700\n",
      "\n",
      "Epoch 00006: loss improved from 0.74179 to 0.71632, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.6914 - acc: 0.8729\n",
      "\n",
      "Epoch 00007: loss improved from 0.71632 to 0.69137, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.6651 - acc: 0.8762\n",
      "\n",
      "Epoch 00008: loss improved from 0.69137 to 0.66515, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.6397 - acc: 0.8806\n",
      "\n",
      "Epoch 00009: loss improved from 0.66515 to 0.63973, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.6132 - acc: 0.8838\n",
      "\n",
      "Epoch 00010: loss improved from 0.63973 to 0.61320, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 떠나요 제주도\n",
      "A: 잘 수 있을 거 예요 \n",
      "\n",
      "\n",
      "Q: 머리 어떻게 할까\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "Q: 결혼 했어\n",
      "A: 저 도 듣고 싶어요 \n",
      "\n",
      "\n",
      "processing epoch: 11...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.5874 - acc: 0.8889\n",
      "\n",
      "Epoch 00001: loss improved from 0.61320 to 0.58744, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 10s 80ms/step - loss: 0.5612 - acc: 0.8933\n",
      "\n",
      "Epoch 00002: loss improved from 0.58744 to 0.56125, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.5362 - acc: 0.8988\n",
      "\n",
      "Epoch 00003: loss improved from 0.56125 to 0.53618, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.5144 - acc: 0.9033\n",
      "\n",
      "Epoch 00004: loss improved from 0.53618 to 0.51439, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.4901 - acc: 0.9082\n",
      "\n",
      "Epoch 00005: loss improved from 0.51439 to 0.49007, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4677 - acc: 0.9129\n",
      "\n",
      "Epoch 00006: loss improved from 0.49007 to 0.46774, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.4463 - acc: 0.9173\n",
      "\n",
      "Epoch 00007: loss improved from 0.46774 to 0.44633, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.4297 - acc: 0.9199\n",
      "\n",
      "Epoch 00008: loss improved from 0.44633 to 0.42968, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4104 - acc: 0.9240\n",
      "\n",
      "Epoch 00009: loss improved from 0.42968 to 0.41038, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.3945 - acc: 0.9272\n",
      "\n",
      "Epoch 00010: loss improved from 0.41038 to 0.39447, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 간식 뭐 먹을까\n",
      "A: 저 는 위로 해드리는 로봇 이에요 \n",
      "\n",
      "\n",
      "Q: 바나나 먹어야지\n",
      "A: 저 도 보고 싶어요 \n",
      "\n",
      "\n",
      "Q: 나 만 꿈 없이 사는 거 같아\n",
      "A: 저 는 위로 해드리는 로봇 이에요 \n",
      "\n",
      "\n",
      "processing epoch: 21...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.3782 - acc: 0.9301\n",
      "\n",
      "Epoch 00001: loss improved from 0.39447 to 0.37822, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.3634 - acc: 0.9334\n",
      "\n",
      "Epoch 00002: loss improved from 0.37822 to 0.36337, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.3499 - acc: 0.9363\n",
      "\n",
      "Epoch 00003: loss improved from 0.36337 to 0.34990, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.3373 - acc: 0.9391\n",
      "\n",
      "Epoch 00004: loss improved from 0.34990 to 0.33730, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.3286 - acc: 0.9406\n",
      "\n",
      "Epoch 00005: loss improved from 0.33730 to 0.32860, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.3169 - acc: 0.9426\n",
      "\n",
      "Epoch 00006: loss improved from 0.32860 to 0.31690, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.3033 - acc: 0.9460\n",
      "\n",
      "Epoch 00007: loss improved from 0.31690 to 0.30332, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.2936 - acc: 0.9465\n",
      "\n",
      "Epoch 00008: loss improved from 0.30332 to 0.29359, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.2843 - acc: 0.9488\n",
      "\n",
      "Epoch 00009: loss improved from 0.29359 to 0.28429, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.2851 - acc: 0.9485\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.28429\n",
      "Q: 만나자고 약속 잡는 것 도 귀찮아\n",
      "A: 잘 할 수 있을 거 예요 \n",
      "\n",
      "\n",
      "Q: 기능 좀 알려줘 봐 봐\n",
      "A: 저 는 마음 을 이어주는 위로 봇 입니다 \n",
      "\n",
      "\n",
      "Q: 기분 전환 이 필요해\n",
      "A: 저 도 보고 싶어요 \n",
      "\n",
      "\n",
      "processing epoch: 31...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.2768 - acc: 0.9502\n",
      "\n",
      "Epoch 00001: loss improved from 0.28429 to 0.27682, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.2652 - acc: 0.9515\n",
      "\n",
      "Epoch 00002: loss improved from 0.27682 to 0.26522, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.2572 - acc: 0.9531\n",
      "\n",
      "Epoch 00003: loss improved from 0.26522 to 0.25722, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.2504 - acc: 0.9544\n",
      "\n",
      "Epoch 00004: loss improved from 0.25722 to 0.25037, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.2420 - acc: 0.9553\n",
      "\n",
      "Epoch 00005: loss improved from 0.25037 to 0.24196, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.2379 - acc: 0.9560\n",
      "\n",
      "Epoch 00006: loss improved from 0.24196 to 0.23790, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.2310 - acc: 0.9569\n",
      "\n",
      "Epoch 00007: loss improved from 0.23790 to 0.23104, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.2249 - acc: 0.9577\n",
      "\n",
      "Epoch 00008: loss improved from 0.23104 to 0.22485, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 8s 60ms/step - loss: 0.2208 - acc: 0.9583\n",
      "\n",
      "Epoch 00009: loss improved from 0.22485 to 0.22082, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.2178 - acc: 0.9588\n",
      "\n",
      "Epoch 00010: loss improved from 0.22082 to 0.21779, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 길 에서 헌팅 당했어\n",
      "A: 조심하세요 \n",
      "\n",
      "\n",
      "Q: 나를 힘들게 하는 사람 인데 붙잡고 싶어\n",
      "A: 신경 쓰지 마세요 \n",
      "\n",
      "\n",
      "Q: 귀가 윙 윙거 려\n",
      "A: 남 과 비교 하지 마세요 \n",
      "\n",
      "\n",
      "processing epoch: 41...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.2117 - acc: 0.9597\n",
      "\n",
      "Epoch 00001: loss improved from 0.21779 to 0.21173, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.2064 - acc: 0.9604\n",
      "\n",
      "Epoch 00002: loss improved from 0.21173 to 0.20642, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.2071 - acc: 0.9597\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.20642\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.2004 - acc: 0.9607\n",
      "\n",
      "Epoch 00004: loss improved from 0.20642 to 0.20042, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1984 - acc: 0.9607\n",
      "\n",
      "Epoch 00005: loss improved from 0.20042 to 0.19842, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1938 - acc: 0.9614\n",
      "\n",
      "Epoch 00006: loss improved from 0.19842 to 0.19382, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1914 - acc: 0.9620\n",
      "\n",
      "Epoch 00007: loss improved from 0.19382 to 0.19135, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1876 - acc: 0.9622\n",
      "\n",
      "Epoch 00008: loss improved from 0.19135 to 0.18764, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1850 - acc: 0.9625\n",
      "\n",
      "Epoch 00009: loss improved from 0.18764 to 0.18503, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1825 - acc: 0.9627\n",
      "\n",
      "Epoch 00010: loss improved from 0.18503 to 0.18245, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 그땐 그랬지\n",
      "A: 자신 의 감정 을 주변 사람 들 에게 터 놓고 이야기 해보세요 \n",
      "\n",
      "\n",
      "Q: 내일 만나자고 해볼까\n",
      "A: 스트레스 받으시는 일 있으신 거 죠 \n",
      "\n",
      "\n",
      "Q: 기분 이 이상해\n",
      "A: 저 도 궁금하네요 \n",
      "\n",
      "\n",
      "processing epoch: 51...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1836 - acc: 0.9624\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.18245\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1780 - acc: 0.9634\n",
      "\n",
      "Epoch 00002: loss improved from 0.18245 to 0.17798, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1757 - acc: 0.9636\n",
      "\n",
      "Epoch 00003: loss improved from 0.17798 to 0.17571, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1727 - acc: 0.9641\n",
      "\n",
      "Epoch 00004: loss improved from 0.17571 to 0.17266, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1723 - acc: 0.9638\n",
      "\n",
      "Epoch 00005: loss improved from 0.17266 to 0.17229, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1689 - acc: 0.9640\n",
      "\n",
      "Epoch 00006: loss improved from 0.17229 to 0.16890, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1679 - acc: 0.9645\n",
      "\n",
      "Epoch 00007: loss improved from 0.16890 to 0.16789, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1666 - acc: 0.9644\n",
      "\n",
      "Epoch 00008: loss improved from 0.16789 to 0.16656, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1662 - acc: 0.9646\n",
      "\n",
      "Epoch 00009: loss improved from 0.16656 to 0.16617, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1639 - acc: 0.9643\n",
      "\n",
      "Epoch 00010: loss improved from 0.16617 to 0.16392, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 내 마음 을 모르겠어\n",
      "A: 저 도 모르겠어요 \n",
      "\n",
      "\n",
      "Q: 남친 프사 에 내 사진 없어\n",
      "A: 말 은 뜨겁고 머리 는 차갑게 \n",
      "\n",
      "\n",
      "Q: 꽃바구니 선물 이랑 과일 바구니 선물 뭐 가 좋아\n",
      "A: 저 도 요 \n",
      "\n",
      "\n",
      "processing epoch: 61...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1613 - acc: 0.9651\n",
      "\n",
      "Epoch 00001: loss improved from 0.16392 to 0.16127, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1742 - acc: 0.9629\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.16127\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1822 - acc: 0.9625\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.16127\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1631 - acc: 0.9643\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.16127\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1561 - acc: 0.9657\n",
      "\n",
      "Epoch 00005: loss improved from 0.16127 to 0.15615, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1522 - acc: 0.9664\n",
      "\n",
      "Epoch 00006: loss improved from 0.15615 to 0.15222, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1503 - acc: 0.9662\n",
      "\n",
      "Epoch 00007: loss improved from 0.15222 to 0.15027, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1485 - acc: 0.9666\n",
      "\n",
      "Epoch 00008: loss improved from 0.15027 to 0.14855, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1453 - acc: 0.9670\n",
      "\n",
      "Epoch 00009: loss improved from 0.14855 to 0.14529, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1461 - acc: 0.9669\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.14529\n",
      "Q: 너 미워\n",
      "A: 많이 피곤한 가봐요 \n",
      "\n",
      "\n",
      "Q: 마른 기침 이 계속 나오네\n",
      "A: 저 랑 한 잔 해 요 \n",
      "\n",
      "\n",
      "Q: 머리 에서 열 날거 같다\n",
      "A: 좋은 수면 습관 이네 요 \n",
      "\n",
      "\n",
      "processing epoch: 71...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1429 - acc: 0.9673\n",
      "\n",
      "Epoch 00001: loss improved from 0.14529 to 0.14294, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1409 - acc: 0.9673\n",
      "\n",
      "Epoch 00002: loss improved from 0.14294 to 0.14095, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1407 - acc: 0.9672\n",
      "\n",
      "Epoch 00003: loss improved from 0.14095 to 0.14072, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1395 - acc: 0.9675\n",
      "\n",
      "Epoch 00004: loss improved from 0.14072 to 0.13949, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1386 - acc: 0.9674\n",
      "\n",
      "Epoch 00005: loss improved from 0.13949 to 0.13856, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1435 - acc: 0.9675\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.13856\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1371 - acc: 0.9680\n",
      "\n",
      "Epoch 00007: loss improved from 0.13856 to 0.13714, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1312 - acc: 0.9690\n",
      "\n",
      "Epoch 00008: loss improved from 0.13714 to 0.13117, saving model to model/seq2seq-attention-checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1297 - acc: 0.9691\n",
      "\n",
      "Epoch 00009: loss improved from 0.13117 to 0.12966, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1288 - acc: 0.9694\n",
      "\n",
      "Epoch 00010: loss improved from 0.12966 to 0.12879, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 가족 여행 어디 로 가지\n",
      "A: 저 도 반가워요 \n",
      "\n",
      "\n",
      "Q: 너 이러면 미워한다\n",
      "A: 많이 피곤한 가봐요 \n",
      "\n",
      "\n",
      "Q: 막차 놓쳤다 택시 비 아까워\n",
      "A: 짜지 마세요 \n",
      "\n",
      "\n",
      "processing epoch: 81...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1281 - acc: 0.9695\n",
      "\n",
      "Epoch 00001: loss improved from 0.12879 to 0.12814, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1269 - acc: 0.9695\n",
      "\n",
      "Epoch 00002: loss improved from 0.12814 to 0.12693, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1248 - acc: 0.9696\n",
      "\n",
      "Epoch 00003: loss improved from 0.12693 to 0.12481, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1244 - acc: 0.9701\n",
      "\n",
      "Epoch 00004: loss improved from 0.12481 to 0.12438, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1228 - acc: 0.9698\n",
      "\n",
      "Epoch 00005: loss improved from 0.12438 to 0.12278, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1208 - acc: 0.9701\n",
      "\n",
      "Epoch 00006: loss improved from 0.12278 to 0.12084, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.1185 - acc: 0.9706\n",
      "\n",
      "Epoch 00007: loss improved from 0.12084 to 0.11852, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.1166 - acc: 0.9714\n",
      "\n",
      "Epoch 00008: loss improved from 0.11852 to 0.11661, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.1184 - acc: 0.9706\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.11661\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.1271 - acc: 0.9695\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.11661\n",
      "Q: 명절 스트레스\n",
      "A: 시간 이 참 빨리 흘러가네요 \n",
      "\n",
      "\n",
      "Q: 가스 비 장난 아님\n",
      "A: 지금 모습 도 좋아요 \n",
      "\n",
      "\n",
      "Q: 문 콕 한 듯\n",
      "A: 아무래도 책임 이 뒤따르니까 요 \n",
      "\n",
      "\n",
      "processing epoch: 91...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.1239 - acc: 0.9693\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.11661\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.1179 - acc: 0.9711\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.11661\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 9s 67ms/step - loss: 0.1158 - acc: 0.9709\n",
      "\n",
      "Epoch 00003: loss improved from 0.11661 to 0.11575, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1128 - acc: 0.9718\n",
      "\n",
      "Epoch 00004: loss improved from 0.11575 to 0.11280, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.1217 - acc: 0.9704\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.11280\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1176 - acc: 0.9708\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.11280\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1098 - acc: 0.9723\n",
      "\n",
      "Epoch 00007: loss improved from 0.11280 to 0.10982, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1089 - acc: 0.9725\n",
      "\n",
      "Epoch 00008: loss improved from 0.10982 to 0.10894, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.1091 - acc: 0.9726\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.10894\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1061 - acc: 0.9729\n",
      "\n",
      "Epoch 00010: loss improved from 0.10894 to 0.10612, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 논문 쓰기 힘들다\n",
      "A: 어깨 꾹꾹 힘내세요 \n",
      "\n",
      "\n",
      "Q: 드디어 봄 이 오 나 봐\n",
      "A: 부지런하시네요 \n",
      "\n",
      "\n",
      "Q: 너 말 이 좀 이상하다\n",
      "A: 많이 피곤한 가봐요 \n",
      "\n",
      "\n",
      "processing epoch: 101...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.1038 - acc: 0.9732\n",
      "\n",
      "Epoch 00001: loss improved from 0.10612 to 0.10380, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.1039 - acc: 0.9740\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.10380\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1008 - acc: 0.9742\n",
      "\n",
      "Epoch 00003: loss improved from 0.10380 to 0.10077, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.0989 - acc: 0.9746\n",
      "\n",
      "Epoch 00004: loss improved from 0.10077 to 0.09888, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0974 - acc: 0.9748\n",
      "\n",
      "Epoch 00005: loss improved from 0.09888 to 0.09738, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0958 - acc: 0.9749\n",
      "\n",
      "Epoch 00006: loss improved from 0.09738 to 0.09578, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0970 - acc: 0.9746\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.09578\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 9s 67ms/step - loss: 0.0931 - acc: 0.9755\n",
      "\n",
      "Epoch 00008: loss improved from 0.09578 to 0.09307, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0927 - acc: 0.9760\n",
      "\n",
      "Epoch 00009: loss improved from 0.09307 to 0.09268, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0921 - acc: 0.9764\n",
      "\n",
      "Epoch 00010: loss improved from 0.09268 to 0.09210, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 너무 배 가 불러\n",
      "A: 방심한 순간 변화 가 시작 됩니다 \n",
      "\n",
      "\n",
      "Q: 뒷 통수 제대로 맞음\n",
      "A: 상처 받지 마세요 \n",
      "\n",
      "\n",
      "Q: 만나면 싸워\n",
      "A: 자책 하지 마세요 \n",
      "\n",
      "\n",
      "processing epoch: 111...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.0927 - acc: 0.9758\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.09210\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0884 - acc: 0.9765\n",
      "\n",
      "Epoch 00002: loss improved from 0.09210 to 0.08844, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.0862 - acc: 0.9774\n",
      "\n",
      "Epoch 00003: loss improved from 0.08844 to 0.08622, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0855 - acc: 0.9773\n",
      "\n",
      "Epoch 00004: loss improved from 0.08622 to 0.08554, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.0856 - acc: 0.9773\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.08554\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0829 - acc: 0.9781\n",
      "\n",
      "Epoch 00006: loss improved from 0.08554 to 0.08295, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.0831 - acc: 0.9781\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.08295\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0814 - acc: 0.9784\n",
      "\n",
      "Epoch 00008: loss improved from 0.08295 to 0.08143, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0820 - acc: 0.9783\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.08143\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.0818 - acc: 0.9779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: loss did not improve from 0.08143\n",
      "Q: 독서 좀 해야겠어\n",
      "A: 자책 하지 마세요 \n",
      "\n",
      "\n",
      "Q: 내 친구 에게 내 험담 을 하다니\n",
      "A: 진짜 나빴네요 \n",
      "\n",
      "\n",
      "Q: 다시 태어나도 챗봇 할래\n",
      "A: 저 는 사람 으로 태어나고 싶어요 \n",
      "\n",
      "\n",
      "processing epoch: 121...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.0790 - acc: 0.9789\n",
      "\n",
      "Epoch 00001: loss improved from 0.08143 to 0.07900, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0807 - acc: 0.9789\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.07900\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0805 - acc: 0.9785\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.07900\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.0741 - acc: 0.9803\n",
      "\n",
      "Epoch 00004: loss improved from 0.07900 to 0.07415, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.0992 - acc: 0.9760\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.07415\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0810 - acc: 0.9790\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.07415\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0766 - acc: 0.9794\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.07415\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0706 - acc: 0.9808\n",
      "\n",
      "Epoch 00008: loss improved from 0.07415 to 0.07064, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0668 - acc: 0.9819\n",
      "\n",
      "Epoch 00009: loss improved from 0.07064 to 0.06684, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 9s 71ms/step - loss: 0.0651 - acc: 0.9821\n",
      "\n",
      "Epoch 00010: loss improved from 0.06684 to 0.06511, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 나 비만 이야\n",
      "A: 상처 받지 마세요 \n",
      "\n",
      "\n",
      "Q: 남편 이 집안일 을 너무 잘 해\n",
      "A: 이상 적 인 남편 이네 요 \n",
      "\n",
      "\n",
      "Q: 떠나요 제주도\n",
      "A: 두근거리겠네요 \n",
      "\n",
      "\n",
      "processing epoch: 131...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0646 - acc: 0.9825\n",
      "\n",
      "Epoch 00001: loss improved from 0.06511 to 0.06461, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0642 - acc: 0.9825\n",
      "\n",
      "Epoch 00002: loss improved from 0.06461 to 0.06422, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0623 - acc: 0.9831\n",
      "\n",
      "Epoch 00003: loss improved from 0.06422 to 0.06231, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0618 - acc: 0.9829\n",
      "\n",
      "Epoch 00004: loss improved from 0.06231 to 0.06184, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.0633 - acc: 0.9829\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.06184\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0600 - acc: 0.9835\n",
      "\n",
      "Epoch 00006: loss improved from 0.06184 to 0.06001, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.0585 - acc: 0.9838\n",
      "\n",
      "Epoch 00007: loss improved from 0.06001 to 0.05854, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.0570 - acc: 0.9843\n",
      "\n",
      "Epoch 00008: loss improved from 0.05854 to 0.05701, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0556 - acc: 0.9844\n",
      "\n",
      "Epoch 00009: loss improved from 0.05701 to 0.05560, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.0537 - acc: 0.9852\n",
      "\n",
      "Epoch 00010: loss improved from 0.05560 to 0.05370, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 그래도 좀 기대했는데\n",
      "A: 상대 에게 바라는 기대는 자신 을 슬프게 해 요 \n",
      "\n",
      "\n",
      "Q: 뭐 하는지 궁금해\n",
      "A: 일해 요 \n",
      "\n",
      "\n",
      "Q: 나 만 친구 라고 생각 한 건가\n",
      "A: 뭐라고 대답 할지 고민 이에요 \n",
      "\n",
      "\n",
      "processing epoch: 141...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0537 - acc: 0.9849\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.05370\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 9s 67ms/step - loss: 0.0556 - acc: 0.9846\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.05370\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0518 - acc: 0.9859\n",
      "\n",
      "Epoch 00003: loss improved from 0.05370 to 0.05184, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0563 - acc: 0.9845\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.05184\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0518 - acc: 0.9857\n",
      "\n",
      "Epoch 00005: loss improved from 0.05184 to 0.05183, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0510 - acc: 0.9859\n",
      "\n",
      "Epoch 00006: loss improved from 0.05183 to 0.05096, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0541 - acc: 0.9852\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.05096\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.0522 - acc: 0.9854\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.05096\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0488 - acc: 0.9864\n",
      "\n",
      "Epoch 00009: loss improved from 0.05096 to 0.04879, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0476 - acc: 0.9868\n",
      "\n",
      "Epoch 00010: loss improved from 0.04879 to 0.04757, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 목소리 좋은 사람 이 좋아\n",
      "A: 저 도 듣고 싶네요 \n",
      "\n",
      "\n",
      "Q: 미끄러질 뻔했어\n",
      "A: 다치지 않으셨나 걱정 이네 요 \n",
      "\n",
      "\n",
      "Q: 나 한테 만은 완전 솔직했으면\n",
      "A: 믿음 이 가장 중요하죠 \n",
      "\n",
      "\n",
      "processing epoch: 151...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0471 - acc: 0.9871\n",
      "\n",
      "Epoch 00001: loss improved from 0.04757 to 0.04712, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.0477 - acc: 0.9866\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.04712\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0446 - acc: 0.9874\n",
      "\n",
      "Epoch 00003: loss improved from 0.04712 to 0.04460, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0439 - acc: 0.9875\n",
      "\n",
      "Epoch 00004: loss improved from 0.04460 to 0.04391, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.0429 - acc: 0.9882\n",
      "\n",
      "Epoch 00005: loss improved from 0.04391 to 0.04286, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.0417 - acc: 0.9884\n",
      "\n",
      "Epoch 00006: loss improved from 0.04286 to 0.04169, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0399 - acc: 0.9893\n",
      "\n",
      "Epoch 00007: loss improved from 0.04169 to 0.03988, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0418 - acc: 0.9885\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.03988\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0397 - acc: 0.9890\n",
      "\n",
      "Epoch 00009: loss improved from 0.03988 to 0.03973, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0385 - acc: 0.9888\n",
      "\n",
      "Epoch 00010: loss improved from 0.03973 to 0.03853, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 다 내 잘못 인 것 같아\n",
      "A: 아니에요 너무 자책 하지 마세요 \n",
      "\n",
      "\n",
      "Q: 무슨 향수 가 좋을까\n",
      "A: 어울리는 향수 가 있을 거 예요 \n",
      "\n",
      "\n",
      "Q: 너무 많이 먹었어\n",
      "A: 소 화제 드세요 \n",
      "\n",
      "\n",
      "processing epoch: 161...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 8s 65ms/step - loss: 0.0389 - acc: 0.9890\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.03853\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0365 - acc: 0.9901\n",
      "\n",
      "Epoch 00002: loss improved from 0.03853 to 0.03653, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.0363 - acc: 0.9902\n",
      "\n",
      "Epoch 00003: loss improved from 0.03653 to 0.03627, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0354 - acc: 0.9903\n",
      "\n",
      "Epoch 00004: loss improved from 0.03627 to 0.03543, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0338 - acc: 0.9902\n",
      "\n",
      "Epoch 00005: loss improved from 0.03543 to 0.03380, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.0341 - acc: 0.9904\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.03380\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.0325 - acc: 0.9907\n",
      "\n",
      "Epoch 00007: loss improved from 0.03380 to 0.03250, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.0318 - acc: 0.9911\n",
      "\n",
      "Epoch 00008: loss improved from 0.03250 to 0.03182, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0309 - acc: 0.9913\n",
      "\n",
      "Epoch 00009: loss improved from 0.03182 to 0.03086, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.0313 - acc: 0.9913\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.03086\n",
      "Q: 결혼 해도 되나\n",
      "A: 능력 이 있으면 하면 되죠 \n",
      "\n",
      "\n",
      "Q: 나 좀 칭찬 해줘\n",
      "A: 지금 도 잘 하고 있어요 \n",
      "\n",
      "\n",
      "Q: 말 을 이해 를 못 해\n",
      "A: 노력 하겠습니다 \n",
      "\n",
      "\n",
      "processing epoch: 171...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.0312 - acc: 0.9915\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.03086\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0349 - acc: 0.9903\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.03086\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0312 - acc: 0.9916\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.03086\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.0293 - acc: 0.9922\n",
      "\n",
      "Epoch 00004: loss improved from 0.03086 to 0.02932, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0282 - acc: 0.9923\n",
      "\n",
      "Epoch 00005: loss improved from 0.02932 to 0.02817, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0278 - acc: 0.9927\n",
      "\n",
      "Epoch 00006: loss improved from 0.02817 to 0.02778, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.0274 - acc: 0.9924\n",
      "\n",
      "Epoch 00007: loss improved from 0.02778 to 0.02739, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.0274 - acc: 0.9928\n",
      "\n",
      "Epoch 00008: loss improved from 0.02739 to 0.02736, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0243 - acc: 0.9935\n",
      "\n",
      "Epoch 00009: loss improved from 0.02736 to 0.02430, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0239 - acc: 0.9939\n",
      "\n",
      "Epoch 00010: loss improved from 0.02430 to 0.02391, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 나 오늘 상 받았 지롱\n",
      "A: 축하 드려요 \n",
      "\n",
      "\n",
      "Q: 방학 에 만날 사람 이 없네\n",
      "A: 먼저 사람 들 이랑 연락 해서 놀러 가는 건 어때요 \n",
      "\n",
      "\n",
      "Q: 나 요즘 정신 놓고 살 고 있는 거 같아\n",
      "A: 정신 차리세요 \n",
      "\n",
      "\n",
      "processing epoch: 181...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.0252 - acc: 0.9935\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.02391\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0245 - acc: 0.9935\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.02391\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0230 - acc: 0.9940\n",
      "\n",
      "Epoch 00003: loss improved from 0.02391 to 0.02301, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0242 - acc: 0.9936\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.02301\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.0224 - acc: 0.9940\n",
      "\n",
      "Epoch 00005: loss improved from 0.02301 to 0.02244, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0211 - acc: 0.9943\n",
      "\n",
      "Epoch 00006: loss improved from 0.02244 to 0.02112, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0216 - acc: 0.9943\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.02112\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.0187 - acc: 0.9953\n",
      "\n",
      "Epoch 00008: loss improved from 0.02112 to 0.01870, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.0198 - acc: 0.9948\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.01870\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0212 - acc: 0.9944\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.01870\n",
      "Q: 밥 잘 사주는 예쁜 누나 어디 없나\n",
      "A: 그 분 이 나타나면 꼭 잡으세요 \n",
      "\n",
      "\n",
      "Q: 금 사빠 인가\n",
      "A: 호의 인지 호감 인지 헷갈리나요 \n",
      "\n",
      "\n",
      "Q: 면세 에서 뭐 사지\n",
      "A: 제 선물 사오세요 \n",
      "\n",
      "\n",
      "processing epoch: 191...\n",
      "Epoch 1/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.0208 - acc: 0.9943\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.01870\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.0185 - acc: 0.9950\n",
      "\n",
      "Epoch 00002: loss improved from 0.01870 to 0.01848, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0175 - acc: 0.9959\n",
      "\n",
      "Epoch 00003: loss improved from 0.01848 to 0.01754, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0192 - acc: 0.9950\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.01754\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.0177 - acc: 0.9955\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.01754\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0174 - acc: 0.9955\n",
      "\n",
      "Epoch 00006: loss improved from 0.01754 to 0.01739, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0178 - acc: 0.9952\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.01739\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0248 - acc: 0.9933\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.01739\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.0193 - acc: 0.9950\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.01739\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.0167 - acc: 0.9958\n",
      "\n",
      "Epoch 00010: loss improved from 0.01739 to 0.01672, saving model to model/seq2seq-attention-checkpoint.ckpt\n",
      "Q: 멍 때리는 중\n",
      "A: 잠깐 씩 멍 때리는것도 정신건강 에 좋아요 \n",
      "\n",
      "\n",
      "Q: 나 친구 들 한테 인정받고 싶어\n",
      "A: 지금 도 인정받고 있어요 \n",
      "\n",
      "\n",
      "Q: 맛있는 거 먹고 싶은데 살 찔까봐 걱정 돼\n",
      "A: 먹고 운동 하세요 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'processing epoch: {epoch * 10 + 1}...')\n",
    "    seq2seq.fit([question_padded, answer_in_padded],\n",
    "                answer_out_one_hot,\n",
    "                epochs=10,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                callbacks=[checkpoint]\n",
    "               )\n",
    "    # 랜덤한 샘플 번호 추출\n",
    "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
    "\n",
    "    # 예측 성능 테스트\n",
    "    for idx in samples:\n",
    "        question_inputs = question_padded[idx]\n",
    "        # 문장 예측\n",
    "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
    "        \n",
    "        # 변환된 인덱스를 문장으로 변환\n",
    "        results = convert_index_to_text(results, END_TOKEN)\n",
    "        \n",
    "        print(f'Q: {questions[idx]}')\n",
    "        print(f'A: {results}\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc963946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124, 170, 347,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자연어 (질문 입력) 대한 전처리 함수\n",
    "def make_question(sentence):\n",
    "    sentence = clean_and_morph(sentence)\n",
    "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "    return question_padded\n",
    "\n",
    "make_question('오늘 날씨 어때?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5a0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇\n",
    "def run_chatbot(question):\n",
    "    question_inputs = make_question(question)\n",
    "    results = make_prediction(seq2seq, question_inputs)\n",
    "    results = convert_index_to_text(results, END_TOKEN)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03577463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< 말을 걸어 보세요!\n",
      "밥은 먹었니\n",
      ">> 챗봇 응답: 단맛 도 있을 거 예요 \n",
      "<< 말을 걸어 보세요!\n",
      "오늘 날씨 어때\n",
      ">> 챗봇 응답: 내일 은 오늘 보다 나을 거 예요 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/fxl3_n31121f16yj69fbrb_m0000gn/T/ipykernel_19251/983239381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<< 말을 걸어 보세요!\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>> 챗봇 응답: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    979\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             )\n\u001b[0;32m--> 981\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input('<< 말을 걸어 보세요!\\n')\n",
    "    if user_input == 'q':\n",
    "        break\n",
    "    print('>> 챗봇 응답: {}'.format(run_chatbot(user_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a009e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fae71bd6",
   "metadata": {},
   "source": [
    "## 허깅페이스 Transformer 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11f9fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.4.0\n",
      "  Using cached torch-1.4.0-cp38-none-macosx_10_9_x86_64.whl (81.2 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.4.0\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: six in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
     ]
    }
   ],
   "source": [
    "# 허깅페이스 트렌스포머 설치\n",
    "!pip install torch==1.4.0\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1054069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bab7a31ad854bf29f943e69ae4a396d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7c602ae7ce477d85df3cd2cf4bf449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c03e6ea14b94adbb68994c9f8b2e51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba385585d16f4a46a6a8c0fe5dd4f956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블: POSITIVE, score: 1.0\n",
      "레이블: POSITIVE, score: 1.0\n",
      "레이블: NEGATIVE, score: 1.0\n",
      "레이블: NEGATIVE, score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 영문 감성분석\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "data = [\"This is what a true masterpiece looks like\", \n",
    "     \"brilliant film, hard to better\",\n",
    "     \"Are you kidding me. A horrible movie about horrible people.\",\n",
    "     \"the plot itself is also very boring\"]\n",
    "results = classifier(data)\n",
    "for result in results:\n",
    "    print(f\"레이블: {result['label']}, score: {round(result['score'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49bf9cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.6286846399307251}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#한글 감성 분석\n",
    "classifier(\"나는 수학이 어렵다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4780fa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79ea94f17df48faa0cbea752ee8fcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cff2f24eb2c4627b30289f114a4bdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb666a2515fa4ca99468af11654ff24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bba6070eb240f0b67f437937d39548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d54f75bba64145b3df544a5efc88ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.33545368909835815}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다국어 모델 불러오기\n",
    "classifier = pipeline('sentiment-analysis', \n",
    "                      model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "classifier(\"나는 수학이 어렵다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ae37a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 이 영화 최고, 레이블: 5 stars, score: 0.82\n",
      "문장: 너무 지루하다, 레이블: 3 stars, score: 0.381\n",
      "문장: 또 보고싶은 최고의 걸작이다., 레이블: 5 stars, score: 0.94\n",
      "문장: 내 취향은 아니다., 레이블: 2 stars, score: 0.338\n"
     ]
    }
   ],
   "source": [
    "# 감성분석(다국어)\n",
    "classifier = pipeline('sentiment-analysis', \n",
    "                      model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "data = [\"이 영화 최고\", \n",
    "     \"너무 지루하다\",\n",
    "     \"또 보고싶은 최고의 걸작이다.\",\n",
    "     \"내 취향은 아니다.\"]\n",
    "\n",
    "results = classifier(data)\n",
    "\n",
    "for i,result in enumerate(results):\n",
    "    print(f\"문장: {data[i]}, 레이블: {result['label']}, score: {round(result['score'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c7c527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce864d3b5ee04ed888bd662b5ce00d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5134e4ffe9e454184470baa8941b8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae05c5d61394e7c80e2111225166fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3455213ea84375958e665d97d5b1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82ad4ede5e64f9d876c279941c0ddd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: What is TensorFlow?, 응답: 'Google Brain's second-generation system', score: 0.801\n",
      "질문: When is TensorFlow 2.0 announced?, 응답: 'Jan 2019', score: 0.771\n"
     ]
    }
   ],
   "source": [
    "# 질의응답\n",
    "# https://en.wikipedia.org/wiki/TensorFlow 텐서플로 소개 글 중 일부\n",
    "from transformers import pipeline\n",
    "nlp = pipeline(\"question-answering\")\n",
    "data = r\"\"\"\n",
    "TensorFlow is Google Brain's second-generation system. Version 1.0.0 was released on February 11, 2017.[14] While the reference implementation runs on single devices, TensorFlow can run on multiple CPUs and GPUs (with optional CUDA and SYCL extensions for general-purpose computing on graphics processing units).[15] TensorFlow is available on 64-bit Linux, macOS, Windows, and mobile computing platforms including Android and iOS.\n",
    "Its flexible architecture allows for the easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices.\n",
    "TensorFlow computations are expressed as stateful dataflow graphs. The name TensorFlow derives from the operations that such neural networks perform on multidimensional data arrays, which are referred to as tensors. During the Google I/O Conference in June 2016, Jeff Dean stated that 1,500 repositories on GitHub mentioned TensorFlow, of which only 5 were from Google.[16]\n",
    "In December 2017, developers from Google, Cisco, RedHat, CoreOS, and CaiCloud introduced Kubeflow at a conference. Kubeflow allows operation and deployment of TensorFlow on Kubernetes.\n",
    "In March 2018, Google announced TensorFlow.js version 1.0 for machine learning in JavaScript.[17]\n",
    "In Jan 2019, Google announced TensorFlow 2.0.[18] It became officially available in Sep 2019.[19]\n",
    "In May 2019, Google announced TensorFlow Graphics for deep learning in computer graphics.[20]\n",
    "\"\"\"\n",
    "q1 = \"What is TensorFlow?\"\n",
    "result = nlp(question=q1, context=data)\n",
    "print(f\"질문: {q1}, 응답: '{result['answer']}', score: {round(result['score'], 3)}\")\n",
    "\n",
    "q2 = \"When is TensorFlow 2.0 announced?\"\n",
    "result = nlp(question=\"When is TensorFlow 2.0 announced?\", context=data)\n",
    "print(f\"질문: {q2}, 응답: '{result['answer']}', score: {round(result['score'], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466e526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8180aa352fd4fb1a52623602bb76b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97043ad399e415fbe7e9b2114bba269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c04c623dc8a40b8b4981ed5d2edf6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8d2c98a9c9490eb1956c0c3be540d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0841732b93c1492cb3288231e1b33cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I love you, I will never forget you.'}]\n"
     ]
    }
   ],
   "source": [
    "#문장 생성\n",
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "data = \"I love you, I will\"\n",
    "print(text_generator(data, max_length=10, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7fd268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1b4b05e225426690fe3657a8bc251c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58313034bbe34bcc84b80087e5135205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d048b7dc67e44afa94dfb9ded33cb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9798f655b88a49969908aa9eb8b9288e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cc01bb52a24b67bf86dfb9c24fbae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \" TensorFlow is Google Brain's second-generation system . Version 1.0.0 was released on February 11, 2017 . It is available on 64-bit Linux, macOS, Windows, and mobile platforms including Android and iOS .\"}]\n"
     ]
    }
   ],
   "source": [
    "#문장 요약\n",
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "data =\"\"\"\n",
    "TensorFlow is Google Brain's second-generation system. Version 1.0.0 was released on February 11, 2017.[14] While the reference implementation runs on single devices, TensorFlow can run on multiple CPUs and GPUs (with optional CUDA and SYCL extensions for general-purpose computing on graphics processing units).[15] TensorFlow is available on 64-bit Linux, macOS, Windows, and mobile computing platforms including Android and iOS.\n",
    "Its flexible architecture allows for the easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices.\n",
    "TensorFlow computations are expressed as stateful dataflow graphs. The name TensorFlow derives from the operations that such neural networks perform on multidimensional data arrays, which are referred to as tensors. During the Google I/O Conference in June 2016, Jeff Dean stated that 1,500 repositories on GitHub mentioned TensorFlow, of which only 5 were from Google.[16]\n",
    "In December 2017, developers from Google, Cisco, RedHat, CoreOS, and CaiCloud introduced Kubeflow at a conference. Kubeflow allows operation and deployment of TensorFlow on Kubernetes.\n",
    "In March 2018, Google announced TensorFlow.js version 1.0 for machine learning in JavaScript.[17]\n",
    "In Jan 2019, Google announced TensorFlow 2.0.[18] It became officially available in Sep 2019.[19]\n",
    "In May 2019, Google announced TensorFlow Graphics for deep learning in computer graphics.[20]\n",
    "\"\"\"\n",
    "\n",
    "print(summarizer(data, max_length=50, min_length=10, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21117fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59d3dd9c",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4957d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting transformers==3.5.0\n",
      "  Downloading transformers-3.5.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (0.0.45)\n",
      "Collecting tokenizers==0.9.3\n",
      "  Using cached tokenizers-0.9.3-cp38-cp38-macosx_10_11_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (2021.4.4)\n",
      "Collecting sentencepiece==0.1.91\n",
      "  Using cached sentencepiece-0.1.91-cp38-cp38-macosx_10_6_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (4.59.0)\n",
      "Requirement already satisfied: numpy in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (1.19.5)\n",
      "Requirement already satisfied: packaging in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (20.9)\n",
      "Requirement already satisfied: requests in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (2.25.1)\n",
      "Requirement already satisfied: filelock in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: protobuf in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from transformers==3.5.0) (3.17.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers==3.5.0) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from protobuf->transformers==3.5.0) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.5.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.5.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.5.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==3.5.0) (4.0.0)\n",
      "Requirement already satisfied: joblib in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==3.5.0) (1.0.1)\n",
      "Requirement already satisfied: click in /Users/adam/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
      "Installing collected packages: tokenizers, sentencepiece, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.9.1\n",
      "    Uninstalling transformers-4.9.1:\n",
      "      Successfully uninstalled transformers-4.9.1\n",
      "Successfully installed sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==3.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb26e81",
   "metadata": {},
   "source": [
    "### Subword Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb5d042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e6e833453a42b79f321fa5c8a4ebc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ae9d251b334eedacb5a7f01af5ed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cfcb5be43b4cb1bca647e8754d68a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5388fd13ee6e4721837da8d0878d84dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "### 사전 훈련된 모델 가져오기\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # Bert-base의 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ade215cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "result = tokenizer.tokenize('Here is the sentence I want embeddings for.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2df468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182\n"
     ]
    }
   ],
   "source": [
    "# 단어 조회\n",
    "##embeddings라는 단어는 단어 집합에 존재하지 않으므로 em, ##bed, ##ding, #s로 분리됨\n",
    "#실제로 BERT의 단어 집합에 특정 단어가 있는지 조회하려면 .vocab[]을 통해서 가능\n",
    "#단어 'here'을 조회\n",
    "\n",
    "print(tokenizer.vocab['here'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216ba288",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/fxl3_n31121f16yj69fbrb_m0000gn/T/ipykernel_20960/3459640444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'embeddings'"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a3ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7861\n",
      "8270\n",
      "4667\n",
      "2015\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab['em'])\n",
    "print(tokenizer.vocab['##bed'])\n",
    "print(tokenizer.vocab['##ding'])\n",
    "print(tokenizer.vocab['##s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4831a12e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/fxl3_n31121f16yj69fbrb_m0000gn/T/ipykernel_26782/4048349795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# BERT의 단어 집합을 vocabulary.txt에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vocabulary.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# BERT의 단어 집합을 vocabulary.txt에 저장\n",
    "with open('vocabulary.txt', 'w') as f:\n",
    "  for token in tokenizer.vocab.keys():\n",
    "    f.write(token + '\\n')\n",
    "    \n",
    "df = pd.read_fwf('vocabulary.txt', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d4eed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 30522\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기 :',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965d49e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##ding'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4667].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7606a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[102].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05e7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2858a32e",
   "metadata": {},
   "source": [
    "## BERT를 이용한 네이버 영화 리뷰 감성 분류 - 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbf39c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0749e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68a65b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 39 # EDA에서 추출된 Max Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b52ee071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac8f0955cb14d32a59087e1604bb024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c6b8c",
   "metadata": {},
   "source": [
    "### 토큰나이저 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a682a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 119, 102]\n",
      "['[ C L S ]', '안', '# # 녕', '# # 하', '# # 세', '# # 요', ',', '반', '# # 갑', '# # 습', '# # 니 다', '.', '[ S E P ]']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"안녕하세요, 반갑습니다.\"\n",
    "\n",
    "encode = tokenizer.encode(test_sentence)\n",
    "token_print = [tokenizer.decode(token) for token in encode]\n",
    "\n",
    "print(encode)\n",
    "print(token_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51e79bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 102]\n",
      "[101, 31178, 11356, 102]\n",
      "[CLS] 안녕하세요, 반갑습니다 [SEP]\n",
      "[CLS] Hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "kor_encode = tokenizer.encode(\"안녕하세요, 반갑습니다\")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "# [101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 102]\n",
    "print(eng_encode)\n",
    "# [101, 31178, 11356, 102]\n",
    "print(kor_decode)\n",
    "# [CLS] 안녕하세요, 반갑습니다 [SEP]\n",
    "print(eng_decode)\n",
    "# [CLS] Hello world [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709bf5a8",
   "metadata": {},
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd3ef1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join('./data', \"ratings_train.txt\")\n",
    "DATA_TEST_PATH = os.path.join('/data', \"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "train_data = train_data.dropna()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7118a9",
   "metadata": {},
   "source": [
    "### 특별한 토큰 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dfb43da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'] \n",
      " [100, 102, 0, 101, 103]\n",
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 119, 102]\n",
      "[101, 31178, 11356, 102]\n",
      "[CLS] 안녕하세요, 반갑습니다. [SEP]\n",
      "[CLS] Hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "# 스페셜 토큰\n",
    "print(tokenizer.all_special_tokens, \"\\n\", tokenizer.all_special_ids)\n",
    "\n",
    "# 토크나이저 테스트하기\n",
    "kor_encode = tokenizer.encode(\"안녕하세요, 반갑습니다. \")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "print(eng_encode)\n",
    "print(kor_decode)\n",
    "print(eng_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145824eb",
   "metadata": {},
   "source": [
    "### 토큰나이저 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75459651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "\n",
    "# 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus\n",
    "\n",
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # Construct attn. masks.\n",
    "        \n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids'] # differentiate two sentences\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335416c",
   "metadata": {},
   "source": [
    "### 훈련 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8d51e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/149995 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/adam/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2016: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████| 149995/149995 [04:47<00:00, 521.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 149995, # labels: 149995\n"
     ]
    }
   ],
   "source": [
    "# train_data = train_data[:1000] # for test\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(train_data[\"document\"], train_data[\"label\"]), total=len(train_data)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n",
    "\n",
    "train_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "train_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_movie_inputs = (train_movie_input_ids, train_movie_attention_masks, train_movie_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_movie_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19f471f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101    100    119    119    119   9928  58823  30005  11664   9757\n",
      " 118823  30858  18227 119219    119    119    119    119   9580  41605\n",
      "  25486  12310  20626  23466   8843 118986  12508   9523  17196  16439\n",
      "    102      0      0      0      0      0      0      0      0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[CLS] [UNK]... 포스터보고 초딩영화줄.... 오버연기조차 가볍지 않구나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이: 39\n",
    "input_id = train_movie_input_ids[1]\n",
    "attention_mask = train_movie_attention_masks[1]\n",
    "token_type_id = train_movie_type_ids[1]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50593e",
   "metadata": {},
   "source": [
    "### 분류 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n",
    "                                                name=\"classifier\")\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1] \n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b9d7a",
   "metadata": {},
   "source": [
    "### 학습 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ce174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비하기\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e00569",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tf2_bert_naver_movie\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = cls_model.fit(train_movie_inputs, train_data_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e9f12",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f828f7",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f41b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_TEST_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "test_data = test_data.dropna()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sent, test_label in tqdm(zip(test_data[\"document\"], test_data[\"label\"])):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        test_data_labels.append(test_label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "\n",
    "test_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "test_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_movie_inputs = (test_movie_input_ids, test_movie_attention_masks, test_movie_type_ids)\n",
    "\n",
    "test_data_labels = np.asarray(test_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"num sents, labels {}, {}\".format(len(test_movie_input_ids), len(test_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74382fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cls_model.evaluate(test_movie_inputs, test_data_labels, batch_size=1024)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
